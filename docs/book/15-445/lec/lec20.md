20-01
00:15 - 00:19
so DJ dropped cable his what he wasn't coming
So，DJ Drop Table好像对我说了什么
00:19 - 00:22
his second girlfriend found out about his third girlfriend
他的第⼆任⼥朋友发现了他的第三任⼥朋友
00:23 - 00:25
so he went to Vegas to hide out
So，他跑去拉斯维加斯避难去了
0.250.28
, that's his problem he has to deal with that
让他⾯对疾⻛吧
00:29 - 00:30
so all right
0.30-0.34
I've been gone what what happened to me well
我来讲下我最近身边发⽣的事情
00:35 - 00:36
My wife had a kid
我⽼婆⽣了个⼩孩
0.36-0.41
and in theory
理论上来讲
00:43 - 00:45
yeah so let's be honest here
诚实的来讲
00:46 - 00:48
it doesn't look like me
他看起来和我并不像
00:50 - 00:52
and I'm not sure it's mine yet
我不确定这是不是我的种
00:52 - 00:55
so we're waiting for the paternity tests come back
So，我们正在等待亲⼦鉴定结果
0.55-0.57
so just hold off hold off your all's okay
So，迟点再告诉你们结果
00:57 - 01:01
um the other thing I want to update for you guys is that
我想告诉你们的另⼀件事情是
1.01-1.03
at the beginning this semester ,I said that
在学期⼀开始的时候，我说过
1.03-1.06
I only care about two things my life
我⼈⽣中只关⼼两件事
01:06 - 01:07
number one was my wife
排在第⼀位的是我⽼婆
1.07-1.09
,number two was databases
排在第⼆位的是数据库
01:09 - 01:12
so I have an updated version for everyone now
So，我向你们摊牌了，我变了
01:12 - 01:18
the new version is that my wife is still number one，databases are still number two
在新的榜单中，排第⼀的还是我⽼婆，数据库还是排第⼆
01:18 - 01:21
,and again depending on the paternity test
取决于亲⼦鉴定结果是什么
1.21-1.25
,the the baby is is just you know sort of there, okay
⽬前⼩孩在我⼼中排第三位
01:26 - 01:28
uh I'll say one thing to everyone here
我想跟你们说⼀件事
1.28-1.34
, if do not get pregnant or getting buddy else pregnant before you graduate school
不要在你们毕业前，把⼈搞怀孕
01:34 - 01:34
it is a nightmare
这会是你的噩梦
1.34-1.40
I've done nothing for the last two weeks except cleaning like poop diapers and like vomit
stuff like that
我上两周除了做些奶爸该做的事情以外，其他什么也没做
01:40 - 01:42
it's awful all right sorry
这太可怕了
01:43 - 01:46
my wife is at home now with the kid, all right
我⽼婆现在就在家带⼩孩中
01:46 - 01:48
so for you guys
So，对于你们来说
1.48-1.51
that don't have any newborn children take care of
你们不⽤去照顾新⽣⼉
1.51-1.52
here's what you have to do
这才是你们必须要做的事情
01:52 - 01:55
so this is what's coming up you in in the next month
So，这是你们下个⽉要⾯对的东⻄
1.55-1.59
, homework 4 is due two days from now on Wednesday at midnight
Homework 4两天后就截⽌了
01:59 - 02:03
project 3 what we do at the end of this week on Sunday at midnight
Project 3的截⽌⽇期是这周周⽇
02:03 - 02:06
and then I'll announce this on Piazza and post this on the website
我会将这些信息放在Piazza上
02:07 - 02:16
we'll do the first checkpoint for the extra credit will be on on Sunday November 24th
after the one week after the project 3 is due
我们会在Project 3截⽌后的⼀周来对你们的额外分进⾏第⼀轮检查
02:17 - 02:19
and so what the checkpoint means basically is
So，简单来讲，checkpoint的意思是
2.19-2.23
you submit the URL to the article that you've been working on
你提交下你所写的那篇⽂章的链接
02:23 - 02:30
the myself or the TAS will look at it give you feedback give you suggestions tell you what
looks right and doesn't look right
我或者助教会去看你写的⽂章，并给你⼀些反馈，提供⼀些建议给你，并告诉你，你哪⾥做的
好，哪⾥做的有问题
02:30 - 02:33
and then that'll give you guidance towards the final submission
这会让你朝着最终版本努⼒
02:33 - 02:39
so I'll just say upfront that you won't get full credit for the extra credit unless you submit
the check point
So，除⾮你提交了你的东⻄，不然你前期是拿不到这些额外分的
02:39 - 02:44
right if you just Smith the check if you submit the final thing at the very end without
giving you know that's giving you feedback
如果你最后才交你的东⻄，并且没有⼈给你反馈的话
02:45 - 02:45
you won't get full credit
你就没法拿全这些额外分
2.45-2.48
and I'll update the the document provide information about all these things
我会去更新下这些⽂档，并给你们提供这些信息
02:49 - 02:50
and then after that
接着，在此之后
2.50-2.51
there's one more homework
你们还有⼀个Homework要做
2.51-2.52
and that'll be due in December
它在⼗⼆⽉的时候截⽌
2.52-2.52
and there's one more project
并且，你们还有⼀个Project要做
2.52-2.55
,and that'll be due in December as well
它也是在⼗⼆⽉的时候截⽌
02:55 - 02.55
Okay
懂了吗
2.55-3.02
so Roma's done, any questions
So，我讲完了，你们有任何问题吗
03:02 - 03:02
Okay
03:03 - 03:06
so let's talk about logging
So，我们来讨论下logging
03:07 - 03:10
so the idea of logging and recovery is that
So，logging和recovery的思想是
3.10-3.16
we obviously want to be able to persist any changes we make to the database And
whenever there's a crash or a failure
很明显，当我们遇上崩溃或者故障的时候，我们想要能够持久化我们对数据库所做的任何修改
03:17 - 03:19
so don't understand this problem.
So，如果你不理解这个问题的话
3.19-322
let's talk about the kind of system we've talked about so far
So，我们来回顾下我们⽬前为⽌所讨论过的系统
3.22-3.24
see the problems are
并看下其中存在的问题
03:24 - 03:26
and then we'll go back now and add logging and recovery
接着，我们会回过头去添加logging和recovery功能
3.26-3.30
, and we'll see how to handle the issues with making sure everything is durable and safe
我们会去看下该如何处理这些问题，以确保所有东⻄都是持久化且安全的
03:30 - 03:35
let's say I have a simple, transaction t1 was your R(A) W(A)
假设，我这⾥有⼀个简单的事务T1，它⾥⾯有两个操作，即R(A)和W(A)
03:35 - 03:36
and at a very very beginning
在最开始的时候
3.36-3.38
there's nothing in our buffer pool
我们的buffer pool中什么也没有
3.38-3.39
like we haven't brought anything into memory
我们并没有将任何数据放⼊内存中
3.39-3.43
and we only have one page that has the object A in it out on disk
我们磁盘上只有⼀个page，它上⾯有⼀个对象A
03:44 - 03:46
so when our transaction starts， it does the R(A)
So当我们的事务开始执⾏的时候，它会执⾏R(A)
03:46 - 03:49
and then we go fetch that page from disk and bring that into our buffer pool,
然后，我们会从磁盘中获取这个page，并将它放⼊我们的buffer pool中
3.49-3.53
that's good we know how to do that we've talked about that already
我们知道该如何做到这点，我们之前就已经讲过了
03:54 - 03:55
so now when I want to do the W(A)
So，如果我想去执⾏W(A)
3.55-4.00
I modify the object as it exists in the buffer pool
我会去修改存在于我buffer pool中的这个对象A
04:00 - 04:02
right I make a flip that make me of it and make the change
我对A进⾏了修改
04:03 - 04:05
then now my transaction says I wants to commit
现在，我的事务表示：我想提交事务了
04:07 - 04:08
what has to happen here
这⾥会发⽣什么呢
04:13 - 04:14
what does it commit mean
这⾥的提交意味着什么呢？
4.14-4.15
the application tells us we want to commit
应⽤程序告诉我们，它想去提交事务了
4.15-4.23
when did we tell the outside world that your transactions actually committed
我们该何时告诉外界你的事务实际已经被提交了呢
04:23 - 04:25
well if we immediately say
Well，如果我们⽴刻就说
4.25-4.25
they tell us commit
当应⽤程序告诉我们，它提交了该事务
4.25-4.30
,we immediately say well you don't there's no deadlocks, there's no timestamp violations
or validation issues with your transaction
我们就会⽴刻说：你的事务中不存在死锁问题、并没有违反时间戳顺序，也没有任何验证问题
04:31 - 04:32
if we merely tell now the outside world
如果我们现在只是告诉外界
4.32-4.34
yeah your transactions committed
你的事务已经被提交了
4.34-4.35
what could happen
这会发⽣什么呢？
04:35 - 04:38
well our change is just hanging out here in memory
Well，我们的修改还只是放在内存中
4.38-4.41
again we pass it all our commercial checks that's all fine
并且我们对其进⾏了所有的检查，并没有发现什么问题
04:42 - 04:43
But it's still sitting in memory
但它依然还在内存中
04:43 - 04:50
so now if like the most evil person for databases comes along like the Hitler databases,
it's just Hitler
So，如果有些数据库⽅⾯很坏的⼈来查看这些内容
04:50 - 04.51
if he comes
如果希特勒来了
4.51-4.56
and that's us taps our data center or our machine and we lose power
他⼲掉了我们的数据中⼼或者是我们的机器，让我们的机器断了电
4.56-5.01
then all the changes that were sitting out in involved to memory are gone
那么所有放在内存中的修改就会全部消失
05:01 - 05:02
all right
5.02-5.03
we never wrote anything out the disk
我们永远没机会将内存中这些修改落地到数据库了
05:04 - 05:06
so if we tell the outside world
So，如果我们告诉外界
5.06-5.10
that when you know immediately hey your thing committed and nothing got persisted to
disk
hey，你的事务已经提交了，但你事务所做的任何修改都没有被持久化到磁盘
05:10 - 05:14
we can immediately you know we could lose power right away and lose all our changes
你知道的，因为断电，我们会⽴⻢丢失我们内存中的所有修改
05:14 - 05:17
and now we totally tell outside where we committed,
我们现在已经告诉外界，我们已经提交了该事务
5.17-5.19
but you come back and you're your changes aren't there and that's bad
但当系统恢复正常以后，你发现你所做的修改并没有落地，这就很糟糕
05:19 - 05:22
so this is at a high level is what the problem trying to deal with today
So，从⾼级层⾯来讲，这就是我们今天所试着处理的问题
05:23 - 05:23
all right
5.23-5.26
called crash recovery and the logging schemes
这叫做崩溃恢复和⽇志记录⽅案
5.26-5.28
it was a mechanism we're gonna use to prevent these things
我们使⽤这些机制来防⽌这些事情发⽣
05:29 - 05:42
so the recovery algorithms were talked about today ,are the techniques that the
database system is going to use to ensure that all the changes that transactions make
will guarantee the database is consistent
So，今天我们要讨论的恢复算法是数据库系统所使⽤的⼀种技术，它⽤来确保事务所做的所有
修改，并保证数据库的⼀致性
05:42 - 05:45
all the changes are atomic and all the changes are durable
所有的修改都是原⼦的，并且它们都被持久化了
05:46 - 05:46
right
5.46-5.49
so we care about A C and D in the ACID acronym
So，这⾥我们所关⼼的是ACID中的A、C和D
05:49 - 05:51
we don't care about isolation for we talk about here today
我们今天不会去关⼼隔离级别⽅⾯的事情
5.51-5.53
,because that's sort of handled by the concurrency control protocols
因为这是⽤于并发控制协议处理的
05:53 - 05.56
okay that's worrying about you know who can writes
Ok，这是跟谁可以执⾏写操作才会关⼼的东⻄
5.56-6.00
,this is really about how can we make sure that our changes are atomic consistent and
durable
这是我们如何确保我们所做的修改是具备原⼦性，⼀致性以及持久性的
06:02 - 06:05
so every recovery protocol our mechanism is gonna have two parts
So，我们的恢复协议机制由两部分组成
06:06 - 06:09
the first of all the things we're gonna do at runtime
⾸先，我们要做的所有事情都是在运⾏时做的
6.09-6.12
,while the system is running, while we're executing transactions and queries
当系统正在运⾏时，当我们正在执⾏事务和查询时
06:12 - 06:17
that will well set us up so that if we have to recover after a failure
So，如果我们遇上了故障之后，我们需要对数据库进⾏恢复
06:18 - 06:20
we're able to do that and not lose any any information
我们要能够做到这点，并且不丢失任何信息
06:21- 06:23
so the first part is all the things we do at runtime
So，第⼀部分就是，我们会在运⾏时做这⼀切
06:24 - 06:25
the second part is
第⼆部分则是
6.25-6.27
if after a restart or if after a crash,
当遇上重启或者是崩溃之后
6.27-6.37
how do we use the information that we collected from the first part ,when you're
running normally to go back and put the database back to the correct state
我们该怎样利⽤第⼀部分所搜集的信息，来将数据库回滚到正确的状态
06:37 - 06:39
so today's lecture is focused on the first part,
So，今天这节课的重点是在第⼀部分
6.39-6.45
what do we do at run time to make sure that we can collect the right information ,so
that we can restore the database correctly
我们在运⾏时该做什么才能保证我们搜集到合适的信息，并以此来正确地恢复数据库
06:45 - 06:47
the second part is on Wednesday
第⼆部分则是在周三讲
06:47 - 06:48
if after we crash
当我们发⽣了崩溃后
6.48-6.51
, we look in here and figure out what the hell we actually did
我们会去看下这⾥，并弄清楚这⾥我们实际做了什么
6.51-6.52
and put us back to the correct state
并将⼀切回归正轨
06:54 - 06:59
so for today there's a bunch of stuff we need to talk about before we actually talk about
the method we're gonna use
So，在我们讨论我们要使⽤的⽅法之前，我们需要谈论⼀系列东⻄
06:59 - 07:02
so first we gotta talk about what kind of failures we could have in our system
So，⾸先，我们会去讨论我们在我们的系统中我们可能遇上的故障情况
7.02-7.06
and how can we you know which ones we can can recover not recover from
并弄清楚在哪些情况下我们可以恢复，哪些情况下我们⽆法恢复
07:06 - 07:13
then we're started talking about how we actually going to manage memory and our
buffer pool in a slightly different way than we've talked about so far
接着，我们会去讨论我们实际该如何来管理内存中的buffer pool，我们要讲的这种⽅式和我们
之前讲的有所不同
07:13 - 07:17
so that we can assure that we can again we can recover after a crash
So，这样我们可以确保我们可以从崩溃中恢复
07:18 - 07:20
then we'll talk about two techniques to do database recovery,
然后，我们会讨论两种⽤来恢复数据库的技术
7.20-7.21
the first is shadow paging
第⼀种⽅案是shadow paging
7.21-7.23
the second is write-ahead logging
第⼆种则是Write-Ahead Logging（预写式⽇志）
07:23 - 07:27
the spoiler would be write-ahead logging is the better way
预写式⽇志是⼀种更好的⽅法
7.27-7.30
this way what every single data system actually uses
实际上，这也是所有数据库系统所使⽤的⽅法
07:30 - 07:32
but it's good to know what shadow paging is
但我们也要去了解下什么是shadow paging
7.32-7.35
just to see for historical reasons and see why this is superior
我们要去了解下它出现的历史原因，以及它为什么是优越的
07:35 - 07:39
then we'll talk about how two different types of logging and write-ahead logging
然后，我们会讨论两种不同类型的logging
7.39-7.40
like what's actually in the log record itself
⽐如⽇志记录中有什么东⻄
07:41 - 07:43
and then we'll finish up talking about checkpoints
接着，我们最后会讨论checkpoints
7.43-7.47
what then we'll segue into what we talked about on Wednesday to do a recovery
我们会在周三去讲数据库崩溃恢复
07:47 - 07:47
ok
07:50 - 07:51
all right
7.51-8.01
so the the database system itself is going to be divided so conceptually into different
components based on what the underlying storage device they operate on
So，根据数据库系统所操作的底层存储设备，从概念上来讲，它被分为⼏个不同的组件
08:02 - 08:04
right the buffer pool manager keeps things in memory
buffer pool管理器会将数据保存在内存中
8.04-8.05
the disk manager keep things on disk
磁盘管理器则是将数据放在磁盘中
08:06 - 08:08
right ones volatile ones non-volatile
⼀个是易失性存储设备，另⼀个是⾮易失性存储设备
08:09 - 08:10
and then so so based on that
So，基于此
8.10-8.24
we want to keep track of and understand how can these different components fail based
on or have problems based on the different types of failures we can incur ,while we're
running transactions, while we're running queries
当我们正在执⾏事务和查询的时候，我们想去跟踪因不同类型故障导致不同出现出现问题的原因
08:25 - 08:26
and in the base of that
根据这个
8.26-8.29
we can figure out what do we actually need to support in our recovery protocol
我们可以弄清楚在我们的恢复协议中，我们实际需要⽀持哪些东⻄
08:31 - 08:33
so there's three categories of failures
So，这⾥有3种故障
8.33-8.34
and we'll go through each of these one by one
我们会逐个看下这些故障
8.34-8.37
transaction failures, system failures and storage media failures
即事务故障、系统故障以及存储媒介故障
08:37 - 08:42
so the spoiler or the the heads-up for what I'm talking about
So，我要提的是
8.42-8.44
,we care about the first two
我们所关⼼的是前两种故障
8.44-8.45
the third one is impossible to handle
第三种故障是我们没办法处理的故障
08:46 - 08:47
and we'll see why as we go along
随着我们的讨论，我们会看到为什么会这样
08:49 - 08:53
so transaction failures over all the things we talked about so far, when we talk about
currency control
So，当我们讨论并发控制的时候，我们讨论了各种事务故障
08:54 - 09:04
these are things like when like when the transaction has a deadlock or transaction tries
to update something, that it's not allowed to update or update a value nor certain way
that's not update
⽐如：当事务遇上死锁，或者事务试着去更新我们所不允许更新的东⻄
09:04 - 09:07
right these are things that we can't allow the transaction to continue
如果遇上这些问题，我们不会允许事务继续执⾏下去
9.07-9.09
and therefore we have to abort it and roll back as changes
因此，我们需要中⽌该事务，并回滚它所做的修改
09:09 - 09:16
so again logical errors would be the transactions trying to violate some internal integrity
constraint
So，逻辑错误指的是事务试着去违反某些内部完整性约束
09:16 - 09:20
that's put upon the database, or a referential constraint
或者违反了数据库中的引⽤约束
9.20-9.21
like if you try to insert something,
⽐如：如果你试着插⼊某个东⻄
9.21-9.23
but that's a foreign key reference and that foreign key doesn't exist
但这⾥有⼀个外键引⽤，但该外键并不存在
09:24 - 09:25
then the database system says
那么，数据库系统就会说
9.25-9.27
you can't complete your transaction has to fail
你⽆法完成这项操作，你的事务会失败
09:28 - 09:30
we're gonna make sure all your your changes get rolled back,
我们要确保你所做的所有修改都会被回滚
9.30-9.31
and never persist
并永远不会被落地
9.21-9.33
even though if we you know we start multiple times
即使我们尝试了很多次
09:34 - 09:39
internal state errors are the things we talked about under two-phase locking and
timestamp ordering
内部状态错误其实就是我们讨论两阶段锁和timestamp ordering时所说的东⻄
09:39 - 09:42
right if we have a dead lock between two transactions
如果这两个事务间存在着⼀个死锁
9.42-9.46
we got to kill one of them and abort them rollback all its changes
那我们就需要⼲掉并中⽌其中⼀个事务，接着回滚它所做的修改
09:46 - 09:49
and then you know make sure that then they don't persist after a crash
接着，你要确保，当经历了⼀次崩溃后，它们不会被持久化
09:49 - 09:52
so our database is logging protocol needs to handle both of these,
So，我们数据库中的logging协议需要能够处理这两种错误
9.52-9.53
I think these are sort of obvious
我觉得这两种错误是很明显的
09:55 - 9.57
then we get to actually the system failures
接着，我们要来讲系统故障
9.57-10.01
the hardware failures that we can count for in our protocol as well
我们可以在我们的协议中处理硬件故障
10:01 - 10:05
so the first is the software failure
So，第⼀种是软件故障
10.01-10.07
these are where the the database system itself is buggy
即数据库系统⾃身出了问题
10:08 - 10:11
right there's some crappy code in the database system
数据库系统中有⼀些糟糕的代码
10.11-10.12
and like a divide by zero
⽐如，divide-by-zero异常(1/0这种类似的计算)
10:12 - 10:16
and now the software it's system itself the database system itself crashes
这导致数据库系统⾃身发⽣了崩溃
10:16 - 10:18
right gets a six set of aborts
这导致了它发⽣了中⽌的情况
10:19 - 10:22
and so we need to be able to account for those kind of failures in our database system
So，我们需要能够在我们的数据库系统中处理这些故障
10.22-10.27
and make sure that you know any transaction is still running they get aborted and
rollback correctly
并确保任何正在执⾏的事务会被中⽌并被正确回滚
10:27- 10:32
or any she was actually that did commit before this this error occurred, all this changes
are persistent
或者确保在这个错误发⽣之前，它们所提交的所有修改都已经被持久化了
10:34 - 10:35
the hardware failure is
硬件故障指的是
10.35-10.42
when the actual machine that our database system is running on crashes or ceases to
operate or runs
运⾏着我们数据库系统的那台机器发⽣了崩溃或者停⽌⼯作
10:42 - 10:43
okay
10.43-10.45
this could be someone like tripped over the power cord
这可能是因为某⼈被电源线绊了⼀下，导致断电
10.45-10.49
or like there's a loose wire plugging into the disk drive
或者，磁盘连接线松了
10:49 - 10:50
right the system has a failure
系统就会遇上故障
10.50-10.52
and they can't keep running
系统就没法继续执⾏
10.52-10.54
the operating system you know crashes ，the database system crashes
操作系统就会崩溃，数据库系统也会发⽣崩溃
10:55 - 10:57
and we need to come back and recover the database state
我们需要让系统恢复正常，并恢复数据库状态
10:58 - 11:01
so in order for us to make this you know be it'll handle this
So，为了能够处理这种故障
11.01-11.04
we have to make this fail stop assumption
我们需要制定这种fail-stop假设
11:05 - 11:06
and that as we assume
我们假设
11.06-11.14
that the hardware is not going to suffer a unrecoverable damage，if we have a
hardware failure
如果我们遇上硬件故障，且硬件不会遭受那些不可恢复的损坏
11:14 - 11:15
meaning like
这意味着
11.15-11.17
if we have a spin against hard drive
如果我们有⼀个机械硬盘
11.17-11.19
and there's the needle writing on the Platter
盘⽚上会有⼀个盘针
11:19 - 11:20
if we pull the power
如果我们拉掉电源
11.20-11.26
and the the the needle is not gonna like Kareem into the platter and sort you know mess
you know messing up sectors
盘针就不会损坏盘⽚
11:26 - 11:27
we assume that
我们假设
11.27-11.29
if we crash have a hardware failure
如果我们遇上了硬件故障
11.29-11.31
then we can always come back and recover the correct state
我们始终可以让系统恢复正常，并让数据库恢复正确的状态
11:34 - 11:38
so the last category there is the ones that we can't handle at all in our database system
So，最后⼀种故障是我们根本⽆法在数据库系统中所处理的故障
11:38 - 11:38
simply
简单来讲
11.38-11.42
because the database system although it's you know as great piece of software it is
虽然数据库系统是软件中很棒的那⼀类
11:43 - 11:46
it can't been you know the the pencil is a matter to its own will
11:47 - 11:56
so a non repairable hardware failure would be like the example of the needle crashing
into the platter or like find like the machine on fire and melt all my disks
So，⼀种不可恢复的硬件故障指的是诸如盘针损坏盘⽚，或者是机器着⽕烧化磁盘之类的情况
11:56 - 11:59
no database system can recover from that
没有任何数据库系统可以从这种情况下恢复过来
11:59 - 12:00
right
12.00-12.02
so we're not gonna design our protocol to account for this
So，我们不会去设计能解决这种问题的协议
12.02-12.08
we can do other things like just replicate the database to overcome this
我们可以去做些其他事情，⽐如对数据库进⾏复制以克服这个问题
12.08-12.12
,or maintain archive backups that we can recover if there's a crash
或者，维护数据库副本，如果我们遇上了这种问题，我们就可以使⽤副本恢复过来
12:12 - 12:15
but that's not really recovery and the same we're talking about today
但这并不是我们今天所讨论的恢复
12:16 - 12:18
like if I had to restore it from an archived version
如果我需要通过⼀个归档版本来恢复数据库
12.18-12.20
,that's just backup and restore
这只是通过备份来恢复
12.20-12.24
that's you notice me loading it in from a you know a separate copy
你会注意到我通过数据库的⼀个单独副本来加载它
12:24 - 12:28
that's not doing anything extra special the kind of things we're talking about today to
recover the database State
我们今天不会去讨论⼀些额外的东⻄来恢复数据库状态
12:29 - 12:31
so again we only care about the first 2 failures
So，再说⼀遍，我们只关⼼前两种故障
12.31-12.33
no database system can account for this
没有任何数据库系统可以解决这种存储媒介所发⽣的故障
12:33 - 12:37
but through redundancy which we'll talk about with distributed databases
但通过冗余（我们在讨论分布式数据库的时候会提到）
12.37-12.40
we can try to avoid this and mitigate the issue
我们可以试着避免这种情况，并减轻这种问题所带来的后果
12:43 - 12:44
okay
12.44-12.47
so the entire semester
So，在整个学期中
12.47-12.49
we've been talking about discarding database systems right
我们已经讨论过数据库系统的很多内容了
12:49 - 12:51
and so we've already covered this already
So，我们已经讨论过这个了
12.51-12.53
but now we need to sort of go over it again
但我们现在需要再去看⼀下
12.53-12.56
and see how this is gonna be an issue when we talk about logging and recovery
当我们讨论logging和recovery的时候，我们会看下这个问题是如何出现的
12:56 - 12.59
so again and it's what a disk based database says what
磁盘型数据库是什么
12.59-13.01
,such that the systems of design
在这种类型的数据库系统中
13.01-13.03
,such that primary storage location is assumed to be on disk
它的主要存储位置是在磁盘上
13:04 - 13:08
and at anytime you want to read a record or manipulate a record
每当你想读取⼀条记录或者操作⼀条记录时
13.08-13.12
,you have to first copy it into memory into your buffer pool make your change
你必须先将它放⼊内存中的buffer pool中对它进⾏修改
13:12 - 13:15
and then eventually write it back out the disk in order to persist it
接着，为了持久化它，我们最终要将它落地到磁盘上
13:16 - 13:18
this is the Von neumann structure from the 1950s
这是来⾃于1950年代所提出的冯诺依曼架构
13.18-13.19
it's not specific to database systems
它并不是专⻔针对数据库系统的
13.19-13.24
but it's the operating assumption we're basing our discussion on
但我们的讨论是基于这种操作上的假设
13:24 - 13:29
and there are some special newer hard drives that can you know have CPU cores on the
disk itself
在某些新型定制的硬盘上⾯会有CPU核⼼
13.29-13.31
and you can try to manipulate the data down there
你可以试着通过它们对数据进⾏操作
13:31 - 13:34
but that's just sort of moving the problem somewheres else
但这只是将问题引到了别的地⽅
13.34-13.34
for our purposes
出于我们的⽬的
13.34-13.35
we can ignore that
我们可以将其忽略
13.35-13.37
,and say you know what we want to modify something
并表示如果我们想对某个东⻄进⾏修改
13.37-13.39
,we bring into memory make the change then write it back out to disk
我们就需要将它放⼊内存后再对其进⾏修改，接着，将它写回磁盘
13:41 - 13:42
so the question is gonna be
So，这⾥的问题是
13.42-13.45
when do we actually write those changes out
我们要在什么时候将这些修改写回磁盘
13:46 - 13:49
so when you guys built the buffer pool stuff from before
So，就拿你们之前构建的buffer pool为例
13.49-13.53
,all you're really doing is just saying, all right Will this page should be evicted
你们所做的就是，你们会说这个page是否应该从buffer pool中移除
13:53 - 13:54
it's dirty
如果它是dirty page
13.54-13.56
so therefore I have to write it back out the disk
那么我就需要将它写回磁盘
13:57 - 14:00
and you didn't worry about who actually made that change
你不⽤去关⼼实际是谁对该page进⾏修改
14.00-14.04
and whether it was the right time to actually write that change out the disk
也不⽤去管将该这些修改落地到磁盘时，此时的时机是否合适
14:05 - 14:08
so that's the thing we need to account for in our logging protocols today
So，这就是我们需要在我们的logging协议中所做到的事情
14:09 - 14:16
so the the basic guarantees we need better to ensure in order to provide the atomicity
So，为了提供原⼦性，我们要确保的最基本保证是
14.16-14.17
because it's the in durability guarantees is that
因为在持久性保证中
14:18 - 14:21
if we tell the outside world that their transaction is committed
如果我们告诉外界，它们的事务被提交了
14.21-14.22
meaning
这意味着
14.22-14.24
we send them an acknowledgment say you've committed,
我们向它们发送了⼀条通知，并说你们已经提交了这些事务
14.24-14.27
then all of those changes are persisted and durable forever
那么，所有这些修改都被永久落地到磁盘了
14:27 - 14:30
someone may come and overwrite those changes and update them
有⼈可能会过来覆盖掉这些修改来对这些数据进⾏更新
14.30-14.31
that's fine
这没问题
14.31-14.34
but you know before that
但你知道的，在此之前
14.34-14.37
you know those changes should always persist forever
这些修改应当被永久保存了
14:37 - 14:37
and likewise
同样
14.37-14.39
if any transaction makes changes
如果有任何事务进⾏了修改
14.39-14.41
and those changes make it out the disk
并且这些修改落地到了磁盘
14:41 - 14:44
but then that transaction aborts or doesn't complete correctly before the crash
但接着，在发⽣崩溃之前，该事务被中⽌了或者并没有正确完成
14:45 - 14:47
we need to make sure that we can reverse those changes as well
我们需要确保我们可以将它们所做的修改恢复原状
14:48 - 14:52
so those are the two main guarantees we need to have in our logging protocol
So，这就是我们logging协议中需要做到的两个主要保证
14:52 - 14.59
and the core principles we're going to use to provide these guarantees are undo and redo
为了提供这些保证，我们所要使⽤的核⼼原理就是Undo（撤销）和Redo（重做）
14.59-15.02
which are exactly as they sound
它们的作⽤就和它们的名字⼀样
15:02 - 15:03
so with undo
So，来讲下Undo
15.03-15.12
it's basically information we're going to maintain to allow us to reverse any changes to
an object in the database that a transaction has made
简单来讲，我们要去维护⼀些信息，这些信息可以让我们去恢复事务对数据库中某个对象所做的
任何修改
15:12 - 15:18
so it's like here's what the old guy used to be for this attribute for this tuple and store
that somewhere
So，⽐如：有个⼈之前对这个tuple中的某个属性进⾏了修改，并将它保存在某个地⽅
15:17 - 15:21
so that if I ever need to reverse the change that someone made to it,
So，如果我需要去撤销他对该tuple所做的修改
15.21-15.25
I can go always go put put the old value back in
我通过这些信息始终可以将旧值放回原位
15:25 - 15:27
and then redo is the opposite of that
Redo则与其相反
15.27-15.34
redo is the information needed to reapply a change that a transaction made to an object
in the database
我们需要去维护与Redo相关的信息，通过这些信息我们会重新执⾏某个事务对数据库中的某个
对象所做的修改
15:34 - 15:39
right here's the information on how to say you know here's the change they made at this
given time
这⾥有些信息表示，这些修改是它们在某个时间所做的
15:39 - 15:41
if I ever need to go back and make that change again,
如果我需要回过头去再去执⾏该修改
15.41-15.43
I might redo information tells me how to do this
我可能就需要通过这些Redo信息来告诉我该如何做
15:44 - 15:47
so based on these two principal or primitives
So，基于这两个原则，或者说这两个原语
15.47-15.50
we can now build on this and I'll have to build something more complex
我可以基于此构建出更为复杂的东⻄
15:50 - 15:59
a logging protocol that allows us to generate this information at the right time
logging
logging协议允许我们在正确的时间⽣成这些信息
15.59-16.01
and in the right way to allow us to restore the database after a crash
当经历了崩溃之后，它会以正确的⽅式让我们恢复数据库
16:01 - 16:03
how we're actually gonna use undo and redo,
我们实际该如何使⽤Undo和Redo呢？
16.03-16.06
and when this information guide gets written to disk
当这些信息被写⼊到磁盘的时候
16:06 - 16:12
it's gonna depend on how we're gonna manage disks,sorry I manage dirty pages in our
buffer pool
这取决于我们如何管理我们buffer pool中的dirty page
16:13 - 16:15
so let's look at more complex example here
So，我们来看个更为复杂的例⼦
16:16 - 16:17
you have t1 t2
假设，我们有T1和T2这两个事务
16.17-16.18
t1 does a R(A) W(A)
T1要去执⾏R(A)和W(A)
16.18-16.21
t2 does a R(B) W(B)
T2要去执⾏R(B)和W(B)
16:21 - 16:25
so in this case here, we're not worried about deadlocks or concurrency control ,
So，在这个例⼦中，我们不会去关⼼死锁或者并发控制
16.25-16.28
we just assume that they're allowed to acquire these locks into whatever they need to do
这⾥我们假设，我们允许它们根据它们的需要去获取对应的lock
16:28 - 16:32
we only care about this point it like the low level changes they're making to these objects
这⾥我们关⼼的只是这些事务对这些对象所做的低级层⾯的修改
16:33 - 16:37
so we transaction t1 starts we do a R(A)
So，T1开始执⾏，它会先执⾏R(A)
16:38 - 16:39
there's only one page in our database
我们的数据库中只有⼀个page
16.39-16.42
and so in order to do the R(A)
So，为了执⾏R(A)
16.42-16.43
, we got to first bring into our buffer pool
我们会先将该page放⼊我们的buffer pool
16:43 - 16:45
and then the transaction is allowed to read it
那么这就允许该事务去读取该page了
16:45 - 16:47
then it does the W(A)
接着，它执⾏W(A)
16.47-16.48
and again it's already in our buffer pool
再说⼀遍，因为它已经在我们的buffer pool中了
16.48-16.50
assuming we can get the latch on it
假设，我们可以获取到它对应的latch
16:50 - 16:53
we can go ahead and make our change, updated directly in place
那么，我们就可以对它进⾏修改，直接在buffer pool中对它进⾏更新
16.53-16.55
we were ignoring multi-versioning for now
这⾥我们先不管多版本之类的东⻄
16:56 - 16:58
we make our change right there and then our operation finishes
我们在buffer pool中进⾏我们的修改，这样我们的操作就结束了
16:59 - 17:01
now we have a context switch
现在，我们要进⾏上下⽂切换
17.01-17.03
T2 starts running it does a R(B)
T2开始执⾏，它先执⾏R(B)
17.03-17.04
the page is already in memory
该page已经在内存中了
17:05 - 17:05
so that's fine
So，这很好
17.05-17.07
that happens right away, then it does W(B),
执⾏完R(B)后，它就去执⾏W(B)
17.07-17.08
again already in memory
再说⼀遍，它也已经在内存中了
17.08-17.11
we assume you get the write latch on it
我们假设，你拿到了它对应的write latch
17:11 - 17:13
we can make our change and we're fine
我们可以对它进⾏修改，这就完事了
17:14 - 17:17
so now we go ahead and t2 wants to commit
So，T2现在想进⾏提交
17:18 - 17:19
what needs to happen here
这⾥会发⽣什么呢？
17:20 - 17:22
well there's two decisions we have to make
Well，这⾥我们需要做两个决策
17:23 - 17:24
the first is
第⼀个决策是
17.24-17.27
in order to be able to tell the outside world that our transaction is committed
为了告诉外界我们的事务被提交了
17:28 - 17:36
should we force the the buffer pool to flush out and write out all the changes that it
made for this page out the disk
我们是否该强制让buffer pool将我们对该page所做的修改落地到磁盘上
17:36 - 17:37
yes or no
答案是Yes还是No？
17:38 - 17:39
yes
答案是Yes
17.39-17.40
right because you have to do theirs
因为你必须这么做
17.40-17.41
otherwise if I crash
否则，如果我遇上了崩溃
17.41-17.43
a Hitler comes along ,and it takes to take this away
⽐如发⽣了断电之类的事情，那么buffer pool⾥⾯的东⻄就会丢失
17.43-17.44
,all my changes are gone
我所做的全部修改就都不⻅了
17:45 - 17:46
well what's the issue
Well，这⾥的问题是什么呢？
17:51 - 17:51
correct
说的没错
17.51-17.55
t1 modified a in the same page
T1修改了同⼀个page上的A
17:56 - 18:04
so should I be allowed to write out a page that's been modified by a transaction that has
not committed yet out the disk
So，我是否能够将⼀个未提交事务所做的修改落地到磁盘上？
18:05 - 18:06
he's shaking her head no
他摇了摇他的头，表示No
18.06-18.07
well what's the problem right
Well，问题是什么呢？
18:07 - 18:10
B is in here T two's made that change,
B也在这个page上，T2对B进⾏了修改
18.10-18.10
but he wants to commit
但T2想进⾏提交
18.10-18.11
it's allowed to
我们也允许它进⾏提交
18:12 - 18:16
but there's this other change in here from an uncommitted transaction
但这⾥还有⼀个来⾃未提交事务所做的修改
18:17 - 18:18
so let's say that all right
So，假设
18.18-18.24
well I take it's better for me to write out t2 choose changes ,even though t1 has a
committee yet
即使T1还未被提交，但我将T2所做的修改落地到磁盘，对于我来说，这样更好
18.24-18.25
so I write those out the disk
So，我将它们写出到磁盘
18:27 - 18:30
but now I you know I tell the outside rworld t2 is committed
但现在我告诉外界，T2被提交了
18.30-18.32
,I'll go back to t1
我切换到T1
18.32-18.33
,but now t1 aborts
但现在T1被中⽌了
18:34 - 18:36
so what needs to happen here
So，这⾥会发⽣什么呢？
18:39-18.40
yes
请说
18.42-18.43
right so I need to roll back the transaction
So，我需要回滚事务
18.43-18.46
so I need to roll back the change it made on a
So，我需要回滚T1对A所做的修改
18:46 - 18:48
I can do that memory pretty fast
我可以在内存中很快地执⾏这种回滚操作
18.48-18.49
right that's not a big deal
这没什么⼤不了的
18:49 - 18:56
but I've wrote out the page to you know that existed in with the change that t1 made out
the disk
但你知道的，我已经将这个page落地到磁盘了，但这上⾯还存在着T1对A所做的修改
18:57 - 18.59
so now I got to go make that change in here
So，现在我需要在buffer pool中对该page进⾏修改
18.59-19.03
and then write it out again to reverse the change that I made
接着，将修改过的page落地到磁盘，以此来恢复之前T1对A所做的修改
19:03 - 19:05
what's the problem of that
这样做有什么问题
19:13- 19:14
Exactly
说的没错
19.14-19.15
so he said
So，他表示
19.15-19.17
by the time I get my abort
等到T1中⽌的时候
19.17-19.22
I maybe I've reversed the change here before I overwrite my change out the disk
在我将修改落地到磁盘之前，我可能就已经将此处T1的修改恢复了
19:22 - 19:28
I crash ,now I come back ,I don't have any of this
系统遇上了崩溃，接着恢复了正常，但我丢失了所有数据
19.26-19.28
I only have what's on disk
我只拥有磁盘上的这些东⻄
19:28 - 19:32
and now I have a change from t1 that I that shouldn't be there
磁盘上的page中包含了T1所做的修改，这些修改本不应该存在的
19.32-19.33
but I don't know it shouldn't be there
但我不知道它不应该在⾥⾯
19:33 - 19:38
because I have no extra information to tell me that T1 did not actually commit
因为并没有什么额外信息告诉我T1实际不应该被提交
19:40 - 19:42
so the two things we talked about here
So，这⾥我们要讨论两件事
19:43 - 19:46
where the two decisions we had to make we're here
这⾥我们需要做两个决策
19:46 - 19:53
whether we should require to force the transaction and write out all its dirty pages out
the disk before allowed to commit
在我们允许事务被提交前，我们是否应当强制让这些事务将与它有关的所有dirty page都落地到
磁盘上
19:54 - 20:02
and whether or not we're allowed to copy out a page or a victim a page from buffer pool
from a transaction that has not committed yet
以及在⼀个事务还未提交的情况下，我们是否能够复制⼀个page或者从buffer pool中移除⼀个
page


20-02
20:03 - 20:06
so these two policies are called steal and force
So，这两种策略分别叫做Steal和Force
20:07 - 20:09
so the steal policy says
So，Steal策略指的是
20.09-20.21
whether transaction whether their database systems allows a uncommitted transaction
,to overwrite the most recent committed value of an object in the database out on disk
,before it's allowed to commit
在事务被允许提交前，数据库系统是否允许⼀个未提交的事务覆盖掉数据库中某个对象最近被提
交的值，并将修改落地到磁盘上
20:23 - 20:26
so if you say if steal if you're using a steal policy
So，如果你使⽤的是这种Steal策略
20.26-20.27
then you're allowed to do this
那么，你就能去做这种事情
20:27 - 20:29
if you're using no steal，then it's not allowed
如果你使⽤的是No-Steal策略，那我们就不允许你去做这种事情
20:30 - 20:31
the way to think about this is
思考它的⽅式是
20.31-20.36
if I'm running out of space my buffer pool from one transaction
如果我所执⾏的某个事务耗尽了我buffer pool中的空间
20:35 - 20:43
is that transaction allowed to steal a page in the buffer pool or slot in the buffer pool
from another transaction that has not committed yet
该事务是否允许从另⼀个未提交事务⼿上偷取buffer pool中的⼀个page或者slot呢？
20:44 - 20:46
right that's why it's called steal
这就是为什么这种策略叫做Steal的原因所在
20:48 - 20:49
the force policy says
Force策略表示的是
20.49-20.59
whether we require that all updates that a transaction makes to any object in the
database have to be written to disk first, before it's allowed to commit
在我们允许该事务提交前，DBMS是否要求该事务所做的所有更新都先落地到磁盘上？
21:00 - 21:02
so if you say I'm using the force policy
So，如果你说我使⽤的是Force策略
21.02-21.03
then it's required to do this
那么，我们需要这么做
21:04 - 21:05
if you're using no force
如果你使⽤的是No-Force策略
21.05-21.06
then it's not required
那么，我们不需要这么做
21:09 - 21:12
so forcing is gonna make it our life easier
So，Force策略让我们处理起来更加容易
21.12-21.15
because it's gonna allow us to recover rather quickly
因为这允许我们能够更快地恢复数据库中的内容
21.15-21.18
because we just come back and we see all our changes are there
因为当DBMS恢复正常的时候，我们能够看到磁盘上DBMS发⽣崩溃前我们所做的所有修改
21:19 - 21:24
right we don't have to you know look at any other place to try to redo information to
redo the changes
我们⽆须跑到其他地⽅去查看Redo信息来重新执⾏这些修改
21:25 - 21:26
but the steal policies would be problematic
但Steal策略可能会有点问题
21.26-21.30
because now we're clean writing out changes or transactions that have not committed
因为我们清理了那些未提交事务所落地的修改
21:32 - 21:33
so let's look at one way to do this,
So，我们来看下其中⼀种做法
21.33-21.35
let's look at the no steal force policy right
我们来看下No-Steal+Force策略
21:35 - 21:38
because they're sort of they have a conflicting goals
因为它们要实现的⽬标互相⽭盾
21.38-21.42
and you know you can only choose you know two combinations of these two things
你知道的，你只能由选择这两个东⻄所组成的两种组合
21:43 - 21:44
so No-Steal+Force means that
So，No-Steal+Force策略指的是
21.44-21.46
no-steal says that
No-Steal指的是
21.46-21.51
any uncommitted changes, any changes made by uncommitted transaction cannot be
written a disk
任何未提交事务所做的修改都⽆法落地到磁盘
21:51 - 21:52
and the force says
Force指的是
21.52-21.58
all changes that transaction made have to be written to disk before the transactions
allowed to commit
在该事务被允许提交前，它所做的所有修改都必须落地到磁盘
21:59 - 22:01
so t1 starts does a R(A)
So，T1开始执⾏R(A)
22.01-22.03
we bring that a buffer pool that's fine
我们将该数据放⼊buffer pool中，这没什么问题
22.03-22.04
now we do the W(A)
接着，T1执⾏W(A)
22.04-22.07
update the page in our buffer pool
它会去更新我们buffer pool中所存放的这个page
22:08 - 22:09
then we do a context switch of t2
接着，我们切换到T2
22.09-22.10
t2 does a read
T2会去执⾏R(B)
22.10-22.11
then does the write
接着，它会执⾏W(B)
22.11-22.13
we update the buffer pool
我们会对buffer pool中的B进⾏更新
22.13-22.15
then now wants to go ahead and commit
接着，我们现在想去提交T2
22:16 - 22:17
again the force policy says
Force策略表示
22.17-22.21
that all the changes for this transaction made have to even out the disk
该事务所做的所有修改都必须落地到磁盘
22:21 - 22:26
but we have this change from t1 hanging out here as well
但T1所做的修改依然还挂在buffer pool中
22:26 - 22:26
so we need to get rid of that
So，我们需要摆脱这种情况
22.26-22.28
so what do we need to do
So，我们需要做什么呢
22:30 - 22:32
right copy the page in memory
我们将page复制到内存中
22.32-22.36
right only apply the change that we want, or reverse this other change we don't want
我们只去提交我们想做的修改，或者是撤销那些我们不想要的那些修改
22:37 - 22:39
and then we can go ahead and write that out
接着，我们将该page写出到磁盘
22:42 - 22:44
so now when we when we come back over here,
So，现在我们回到这⾥
22.44-22.46
and we abort t1
我们中⽌了T1
22:47 - 22:53
now it's super trivial for us to reverse the change, that all the change that t1 made,
现在，对我们来说，要撤销T1所做的所有修改，是⼀件很简单的事情
22.53-22.56
because it's just updating this page in memory
因为它刚更新了内存中这个page
22:56 - 23:00
we don't have to go out the disk was you know no dirty dirty change got out there
我们⽆须将该page落地到磁盘，这⾥⾯并不存在其他修改（我们落地的是T2所修改的那个副
本）
23:01- 23:07
so the database system is going to maintain some extra metadata to keep track of the
write set over these different transactions
So，数据库系统会去维护⼀些额外的元数据，以此来跟踪这些不同事务的write set
23:07 - 23:12
you guys already solved this under two-phase locking and and OCC under concurrency
control protocol
你们已经通过两阶段锁、OCC和并发控制协议之类的东⻄解决了这个问题
23:12 - 23:15
so we already have that information about what changes they made to what objects
So，我们已经拥有了这些信息，即这些事务对哪些对象进⾏了修改
23:15 - 23:20
so it's not that big of a deal or extra work we have to do to be able to reverse that
change, when you make that copy
So，当你制作了该副本后，我们⽆须做太多⼯作就能够撤销这些修改
23:21 - 23:22
all right
23.22-23.22
and it's in memory
它是放在内存中的
23.22-23.23
so that should be pretty fast
这样的话，我们处理起来的速度应该很快
23:25 - 23:28
so this seemed like a good idea or a bad idea
So，这看起来是⼀个好主意还是⼀个坏主意呢？
23:31 - 23:34
so that's one what's one good thing about this approach
So，这种⽅案的其中⼀个好处是什么呢？
23.34-23.35
, I've already said it
我之前已经讲过了
23.35-23.38
detector right there
就在这⾥
23:39 - 23:41
it's super trivial to rollback after a crash
即当DBMS发⽣崩溃后进⾏回滚是⼀件⾮常简单的事情
23:42 - 23:43
because there's nothing to rollback
因为这⾥不需要回滚什么东⻄
23.43-23.47
because I know that anything is that's out on disk should be out on disk
因为我知道那些本应在磁盘上的东⻄，就会在磁盘上
23:47 - 23:49
because they're all from committed transactions
因为这些修改都来⾃于那些已经提交的事务
23:54 - 23:56
what's that sorry is there a deadlock between two transactions
你说的是，这两个事务间是否存在死锁
24:15 - 24:17
so his question is
So，他的问题是
24.17-24.17
going back here
回到这⾥
24.17-24.19
in my example here
在我的例⼦中
24.19-24.24
I have one thread or one transaction wants to write out something disk
我有⼀条线程或者⼀个事务想将某个东⻄写出到磁盘
24.24-24.25
it makes one copy
它制作了⼀份副本
24:25 - 24:27
but then another transaction may be committing at the same time
但接着，另⼀个事务可能在同⼀时间进⾏了提交
24.27-24.29
,and it modified the same page
它对同⼀个page进⾏了修改
24.29-24.30
you shouldn't make another copy
你不应该制作另⼀份副本
24:31- 24:31
we can ignore that
我们可以将它忽略
24.31-24.32
we assume that
我们假设
24.32-24.36
I mean you have to have a single latch protect these things
我的意思是你们需要通过⼀个latch来保护这些东⻄
24.36-24.37
there's no way to get around that
我们没有任何办法解决这个问题
24:38 - 24:39
but we can ignore all that here
但我们这⾥可以将它们忽略
24:43 - 24:45
so there's two problems
So，这⾥有2个问题
24:47 - 24:48
actually three problems
实际上是三个问题
24:53 - 24:53
yes
请问
25:01 - 25:03
so you're close
So，你说的很接近
25.03-25.04
these first he said
他表示
25.04-25.06
the now and your processing page to commit
我们所正在处理的这个page现在要被提交到磁盘
25.06-25.08
this copy here it's more work
我们要对这个副本所做的⼯作就会变得更多
25:08 - 25:16
it's on the critical path it's in the critical section of the commit protocol for the
concurrency control mechanism
这是并发控制机制中提交协议⾥的关键部分
25.14-25.16
that becomes more expensive
这样成本会变得更加昂贵
25:16- 25:17
yes absolutely right yes
说的没错
25:19 - 25:21
but more than just CPU cost
但除了CPU成本以外
25.21-25.24
it's actually the you have to write this thing out multiple times now
实际上，你需要将这些东⻄多次写⼊到磁盘
25:25 - 25:27
like so say if you go back if we go here
如果我们回到这⾥
25:27 - 25:30
if t1 didn't actually abort and actually committed
如果T1实际并没有被中⽌，⽽是被提交了的话
25.30-25.33
then in order to get its change to A out the disk
为了让T1对A所做的修改落地到磁盘
25.33-25.35
I'll write it out again
我就要再次将它写⼊到磁盘
25:35 - 25:37
so for every transaction that commits
So，对于每个提交的事务来说
25.37-25.40
I potentially have to write out the same page over and over again
我可能需要反复将同⼀个page写⼊到磁盘
25:41 - 25:41
yes
请问
25:51 - 25:53
Exactly he's actually right
他说的完全没错
25:53 - 25:55
so one big issue with this
So，其中存在的⼀个⼤问题是
25.55-25.56
in MySQL example here,
在MySQL的例⼦中
25.56-25.59
I have one page say it's four kilobytes
我有⼀个4kb⼤⼩的page
25:59 - 26:03
the hardare can guarantee that I can do a atomic four kilobyte page write
硬件可以为我们保证，我可以对⼀个4kb⼤⼩的page执⾏⼀次原⼦性写⼊操作
26:03 - 26:07
but if I update multiple pages, the harbor can't guarantee that for me
但如果我更新多个page，硬件则⽆法为我保证原⼦性
26:07 - 26:09
so I could if I update four pages
So，如果我更新4个page
26.09-26.10
I've read out the first two
我读取了前两个page
26.10-26.12
then I crashed before I get the next two
在我获取下两个page前，我崩溃了
26:12 - 26:13
now I come back
现在，当我的系统恢复正常
26.13-26.15
and I don't have you know I have a torn updates
你知道的，我就会遇上更新撕裂的问题
26:17 - 26:19
so that see that's right that's one big problem
So，这就是⼀个⼤问题
26.19-26.21
there's another big one that's a more nuanced
还有另⼀个更为微妙的⼤问题
26:24 - 26:28
so again I have one page of this this is sort of trivial example
So，在这个简单案例中，我就只有⼀个page
26:29 - 26:31
but in this case here
但在这个例⼦中
26.31-26.32
for a given transaction
对于⼀个给定的事务来说
26.32-26.38
since I can't write out any dirty data from uncommitted transaction to disk
因为我⽆法将未提交事务所修改过的数据写出到磁盘
26:38 - 26:39
that means
这意味着
26.39-26.45
I can my my write set all my transaction has to fit entirely in main memory
我事务相关的所有write set都必须完整的放在主内存中
26:45 - 26:47
so if I have a table has 1 billion tuples
So，如果我的表中有10亿条tuple
26.47-26.49
I have a single query that wants to update all 1 billion tuples
我要执⾏⼀个查询，它想对这10亿条tuple进⾏更新
26:50 - 26:53
but I can only store 1 million tuples in my buffer pool
但我的buffer pool中，我只能存放100万条tuple
26.53-26.57
,then I can't run that transaction in under this system
那么，我⽆法在该系统中执⾏这个事务
26:57 - 27:00
because I'll hit the first 1 million update them that's fine
因为我可以去先获取前100万个tuple，然后对其进⾏更新，这没什么问题
27.00-27.02
then I try to get the million plus one
然后，我试着去获取第100万零⼀个tuple
27:02 - 27:04
and then I'm running on it I ran out of space
然后我对它进⾏修改，但我并没有空间容纳这个tuple
27:09 - 27:10
so he says
So，他表示
27.10-27.13
can't you is there a work around can you write into a temporary spot, yes
我们是否可以将这部分⼯作放⼊⼀个临时空间中，其实是可以的
27.13-27.14
give me two slides
给我两张幻灯⽚的时间
27.14-27.16
that is the solution ,yes
我会给你们展示下解决⽅案
27:16 - 27:18
it's not a good one, but it's one
它虽然不是什么好解决⽅案，但它确实是⼀个解决⽅案
27:20 - 27:21
okay
27.21-27.33
so No Steal+Force is the most easiest way to actually implement a recoverable correct
durable, buffer pool manager and a disk oriented a database system
对于buffer pool管理器和⼀个⾯向磁盘的数据库管理系统来说，No Steal+Force是实现可恢复
的正确持久化最简单的⽅式
27:33 - 27:36
because I don't have to do any redo after a crash,
因为当系统经历崩溃后，我⽆须做任何Redo操作
27.36-27.39
I just come back my database is guaranteeing the correct state
当系统恢复正常后，我的数据库会保证它处于正确的状态
27:41 - 27:45
and I never have to go you know undo anything from an aborted transaction at run time
在运⾏时，我从来都不需要去撤销⼀个中⽌事务所做的任何修改
27.45-27.48
because I know none of us changes ever made it out the disk
因为这些被中⽌的事务所做的修改并没有落地到磁盘上
27:48 - 27:50
but as we said already that
但就如我们之前所说的
27.50-27.55
you can't support transactions that have a write set that exceed the amount of memory
that's available to you
你⽆法⽀持事务的write set超出你可⽤的内存量
27:56 - 27.59
the commit protocol is now more expensive
提交协议的成本则更为昂贵
27.59-28.03
because you have to do all these extra extra work to figure out what things actually
should be written to disk where it's not written disk
因为你需要做些额外⼯作来弄清楚哪些东⻄实际应该落地到磁盘，⽽它并没有落地到磁盘
28:05 - 28:10
and you're doing multiply writes out to disk you know for everything
你会将数据多次写⼊到磁盘
28.10-28.11
that could have just been one write
你也可能只需要写⼊⼀次即可
28:12 - 28:15
now for every single transaction you're writing the same page over and over again
对于每个事务来说，你要将同⼀个page反复写⼊到磁盘
28:15 - 28:16
and if you're an SSD
如果你使⽤的是固态硬盘
28.16-28.18
those things actually can't be written forever
实际上，你不能⼀直这样⼲下去
28.18-28.20
right you can burn out the cells on the SSD
你会耗尽你固态硬盘颗粒的寿命
28:21 - 28:24
you know it's in the hundreds and thousands write per cell
每个颗粒只能承受数百或者数千次写⼊
28:25 - 28:29
but eventually to keep doing this if you're just running a lot you'll burn it out in a short
amount of time
但最终，如果你⼀直⼲这种事情，你的固态硬盘就会在很短的时间内报废
28:32 - 28:34
so nobody actually does what I'm describing here
So，实际上，没有⼈做我这⾥所描述的事情
28:35 - 28:36
right it is the easiest way to implement it,
这是实现它的最简单⽅式
28.36-28.38
but nobody actually does this
但实际没有⼈这样做
28:39 - 28:44
the thing that he alluded to that people have tried before,
他刚刚提到了⼈们之前已经尝试过的东⻄
28.44-28.50
it`s to basically store the changes you're making from uncommitted transactions in a
temporary space
简单来讲，就是将那些未提交事务所做的修改保存到⼀个临时空间中
28:51 - 28:54
and then at some point when the transaction commits
接着，在某个时候，当这些事务提交了
28:54 - 29:01
you somehow resolve the the directory or the page table to now say,
你会以某种⽅式来解析⽬录或者page table，并表示
28.58-29.02
here are actually the correct the latest versions of our pages
实际上，这⾥是我们page的最新版本
29:02 - 29:03
and that way if you crash
如果我们遇上了系统崩溃
29.03-29.07
you just ignore anything that got modified in those temporary buffers
我们只需忽略掉这些临时buffer中所做的修改
29:08 - 29:09
so this is what shadow paging is
So，这就是shadow paging所做的事情
29.09-29.13
we briefly touch about this in the very beginning when we talk about concurrency control
其实我们⼀开始在讲并发控制的时候，我们就简要接触了这个东⻄
29:14 - 29:19
this is one way to do a no steal force buffer pool management system
这是实现⼀个⽀持No-Steal+Force的buffer pool管理系统的⽅式
29.19-29.22
that avoids some of the complications we talked about before
这会避免我们之前讨论过的⼀些复杂问题
29:23 - 29:27
so shadow paging works it's like it's sort of like multi-versioning
So，shadow paging的⼯作⽅式和多版本控制很像
29:28 - 29:30
but at the page level instead of the tuple level
但它是在page层⾯做⽽不是tuple层⾯的
29:31 - 29:33
and there's only going to be two copies at any given time,
在任何给定时间，它都只会有两个副本
29.33-29.35
there's always the master copy,
它始终会有⼀个master副本
29.35-29.39
that's the latest most recently committed version of of the database
它⾥⾯只包含那些最近已落地事务对数据库所做的修改
29:39 - 29:41
and then there's the the shadow copy
接着就是shadow副本
29.41-29.44
that all new transactions are going to end up modifying
它⾥⾯包含的是那些对数据库进⾏了修改但还未提交的事务
29:45 - 29:47
so when a transaction commits
So，当⼀个事务提交的时候
29.47-29.53
, we want a way to atomically switch the the shadow to become the new master
我们想通过⼀种原⼦的⽅式将shadow副本变为⼀个新的master副本
29:54 - 29:55
I mean we can do this in such a way
我的意思是我们可以以某种⽅式做到这⼀点
29.55-29.58
that we don't worry about torn writes, if we're updating multiple pages
如果我们对多个page进⾏更新，我们就⽆须去关⼼更新撕裂的问题
30:00 - 30:09
so unlike in Multi-versioning where we copy every single thing we're going to modify
So，在多版本控制中，我们要去复制每个要修改的东⻄，shadow paging与它不同的地⽅在于
30:09 - 30:11
actually it's like Multi-versioning
实际上，它和多版本控制很像
30.11-30.13
, but instead of doing a tuple of what you're doing at a page level
但我们并不是在tuple层⾯进⾏处理，⽽是在page层⾯进⾏处理
30:14 - 30:18
and you can organize the directory of your pages as a tree structure
你可以将你的page⽬录组织为⼀个树形结构
30:18 - 30:22
so now you only need a cat copy sort of portions of the tree
so 现在你只需要去复制这棵树的⼀部分数据
30:22 - 30:32
and then just do Pat copying to update them in place, or apply them to the the page
table without having to recreate the entire hash table all over again
然后对该副本数据进⾏更新，这样也就⽆须再重新创建⼀个完整的hashtable
30:33 - 30:37
so at the root of this tree is gonna be the database root
So，这棵树的根节点其实是数据库的根节点
30.37-30.40
, that's always gonna point to the latest master version
它指向的始终是最新的master版本数据
30:41 - 30:42
so that means
So，这意味着
30.42-30.44
we can make a bunch of changes to the low portion of the tree,
我们可以对树的较低部分处执⾏⼀系列修改
30.44-30.49
but update the leaves to point into our new pages that we just created
我们要更新叶⼦结点，并让它指向我们刚刚创建的新page
30:49 - 30:52 ！！！！！
and then when we're ready to apply the changes to atomically across all these pages
当我们准备好对这些page进⾏原⼦修改
30.52-30.57
we just swing this database root pointer to now point to our shadow portion of the tree
我们只需将database的root指针指向该树的shadow部分即可
30:57- 31:01
and then all all our changes become immediately visible
那么我们所做的这些修改就会⽴即可⽤
31:02 - 31:03
so a high level looks like this
So，从⾼级层⾯来看，它是⻓这样的
31.03-31.05
again there's this database root
这个是database root
31.05-31.06
,and it points to the master page table
它指向的是master page table
31.06-31.09
,and this master page table points to our pages out on disk
这个master page table指向的是我们磁盘上的page
31:11 - 31:13
so I'm gonna briefly go with this
So，我会简单讲下这个
31.13-31.17
but going through is sort of quickly, but let me just get this get to the example
但我们还是来快速看个例⼦吧
31:18 - 31:21
so say we have a transaction comes along t1
So，假设我们有⼀个事务T1
31.21-31.25
,any transaction that's read-only can go always go to this database root
任何只读型事务都可以跑到database root这⾥
31.25-31.27
, and go to the the master copy and see a consistent version
并查看master page table，然后读取到⼀致的版本数据
31:28 - 31:29
but if we have an updating transaction
但如果我们有⼀个要执⾏更新操作的事务
31.29-31.31
we have to create a shadow page table
我们必须创建⼀个shadow page table
31.31-31.33
,that the transactions going to modify
事务会在这⾥⾯对page进⾏修改
31:33 - 31:34
so at the very beginning
So，在⼀开始的时候
31.34-31.42
the shadow page table, it just all its entries point to the same pages that the master
page points to the master page table points to
shadow page table指向的page与master page table指向的page相同
31:42 - 31:45
so now as this transaction starts modifying pages
So，当现在这个事务开始修改这些page时
31:46 - 31:51
we're going to make a copy of that page into a new location in our temporary space in
on disk
我们会将要修改的这个page的副本复制到磁盘上临时空间中的⼀个新位置
31.51-31.53
, make all our changes there
并在那⾥执⾏我们的修改
31:54 - 31:57
right and we keep doing this for all all the other all the other pages we want to modify
我们对我们其他想要修改的page也进⾏相同的操作
31:58 - 32:02
and then when this transaction says I want to go ahead and commit
接着，当这个事务表示：我想进⾏提交了
32:02 - 32:04
all we need to do is
我们所需要做的就是
32.04-32.06
update this database root which is stored in a single page
更新这个database root，它是保存在⼀个单独page上的
32.06-32.14
to now point to this portion or this patient of the shadow page table
让这个database root指向这个shadow page table的某⼀部分
32:14 - 32:16
so we flush that change out the disk
So，我们将我们做的修改落地到磁盘
32.16-32.20
, and then now it really becomes that becomes once that's durable
⼀旦我们所做的修改持久化到磁盘后
32:20 - 32:21
we then swing that pointer in memory
我们就更新下内存中的指针
32.21-32.24
, and then we now know that everyone can can follow this one
然后所有⼈就可以沿着指针找到这个page了
32:24 - 32:30
so if a new transaction comes along and once it wants to you know want to read what
the latest version is of the database
So，如果有⼀个新事务想去读取数据库中的最新版本数据
32.30-32.32
, it just follows this route and finds the shadow page table
它只需沿着这条路线，找到shadow page table就⾏
32:35 - 32:35
yes
请讲
32:41 - 32:44
questions why database root written to the disk
他的问题是，为什么这个database root要写⼊到磁盘
32:48 - 32:48
right so they crash,
So，如果它们发⽣崩溃
32.48-32.50
right so so I'm here
So，我现在的情况是这样的
32.50-32.52
, by transaction says I want to commit
该事务表示，它想进⾏提交
32:53 - 32:56
I want to tell the outside world I commit it, right
我想告诉外界我提交了这个事务
32:57 - 33:01
so if I don't update this database root
So，如果我不对这个database root进⾏更新
33.01-33.02
,I crash and come back
当系统发⽣崩溃，并恢复正常后
33.02-33.04
,and now I look at my database root
现在，我去查看我的database root
33.04-33.06
and he's pointing to the master page table
它指向的是这个master page table
33.06-33.08
,and all these changes are gone
我们所做的所有修改就都消失不⻅了
33:19 - 33:20
Correct, yes
说的没错，继续
33:29 - 33:33
it's Alama it's I think it's a page number the page ID
我觉得它是page number，即page id
33:34 - 33:36
right that has to be durable
这个必须被持久化
33.36-33.37
because if I crash to come back,
因为当系统崩溃后恢复正常⼯作时
33.37-33.39
if I tell outside world I commit
如果我告诉外界我提交了这个事务
33:40 - 33:41
but then I crash,
但接着，系统发⽣了崩溃
33.41-33.46
I'll assume whatever this thing was pointing out is the root of the page table
这⾥我要指出的东⻄就是该page table的root
33.46-33.48
and that means I told the outside world I committed
这意味着，如果我告诉外界我提交了这个事务
33:48 - 33:51
but now all my changes I made here in the shadow page table are gone
但现在，我在shadow page table中所做的修改都消失不⻅了
33:52 - 33:53
they're still there on disk,
这些修改依然在磁盘上
33.53-33.55
it's just no one can see them there
只是没⼈能看到这些修改⽽已
33.55-33.57
,you can't logically see them
从逻辑上来讲，你⽆法看到这些修改
33:57 - 33:58
so it's as if they didn't exist
就如同它们不存在⼀样
34:15 - 34:16
you quit your question is can you be clever and figure out a way to when you write out
these pages , put a little mark in here to say, yeah you're the latest version
So，你的问题是，当我们写出page到磁盘的时候，是否能给这些page做些⼩标记，以此表示这
些page上的数据是最新的
34:29 - 34:32
so all right so this guy updated three pages
So，假设它更新了3个page
34:33 - 34:39
so I need to now record that , okay you updated three three out of X pages or n pages,
So，我现在需要记录下你更新了这3个page或者n个page
34.39-34.43
to make sure that if I crash come back I see all those changes
以此来确保，如果系统发⽣崩溃，然后恢复正常⼯作后，我还能看到我做的这些修改
34:43 - 34:55 (student)
Yeah, essentially because you know essentially on disk right now, without the according
the data make sure, you have some something like out of some out-of-date pages there
因为现在在磁盘上你会有⼀些过时的page
34.51-34.55
,right use this trick to keep track of whichever the database tells you which ones are the
most up-to-date
通过这种⽅法，数据库可以告诉你哪些page是最新的
34:55 -34:55
yes
没错
34:55 - 34.57 (student)
essentially whatever transaction commits
不管哪个事务被提交了
34.57-34.59
lets you bring some pages out to disk
这会让你将⼀些page刷⼊磁盘
34.59-35.03
with those pages write out to disk for this you may know the timestamps or the
transaction or something
这些page会携带时间戳或者事务之类的信息
35:03 - 35:03
sure
没错
35:07 - 35:10
my database is 100 petabytes
我的数据库⽂件是100PB那么⼤
35:12 - 35:14
that this is one page
我们使⽤⼀个page来保存database root
35.14-35.15
, it has everything I need
它上⾯保存着所有我需要的东⻄
35.15-35.18
,always can always think in extremes
我们总是需要思考极端情况
35.18-35.19
yes
请讲
35:26 - 35:27
excellent
问的不错
35.27-35.27
so he said
So，他表示
35.27-35.29
and in my example here
在我的例⼦中
35.29-35.30
,I have one transaction,
我有⼀个事务
35.30-35.34
what if I have a bunch of transactions at the same time, how does this work
假设同⼀时间我要执⾏⼀⼤堆事务，那它是如何⼯作的呢？
35:34 - 35:40
So you either have to have only one transaction run at time, which SQLite does
So，你可以⼀次只执⾏⼀个事务，这是SQLite的做法
35:42 - 35:44
or you you have to commit them in a batch
或者，你可以批量提交这些事务
35:44 - 35:47
so I say I ignoring two phase locking
So，我之前说过，我们现在不去管两阶段锁相关的事情
35.47-35.49
because all that is orthogonal to this
因为它们俩要解决的都是同⼀个问题
35.49-35.52
assume that you have a way to figure out who's allowed to update what
假设，你有某种⽅式可以弄清楚谁能更新哪个page
35:52 - 35:55
if I have multi transactions within the same batch updating things
如果在同⼀批更新处理⾥⾯涉及多个事务
35:55 - 35.58
I have to wait until they all finish
我必须等到这些事务都结束才⾏
35.58-36.00
then they all get committed
接着，这些事务都被提交了
36.00-36.04
I swing my database root pointer, right, and then it get atomically I can apply
我对我的database root指针进⾏修改，然后我完成了对这些page进⾏的原⼦修改
36:05 - 36:06
so that's one way to do this
So，这是其中⼀种做法
36.06-36.09
,if you assume all transactions are going to finish in a reason amount of time
如果你假设所有的事务都在⼀定时间内完成
36:09 - 36:11
if you have one transaction that takes an hour
如果你有⼀个要花1⼩时执⾏的事务
36.11-36.16
, then you either need to kill it if for a certain amount of time or wait that one hour
before everybody goes it goes ahead and commits
那么你可能需要等⼀段时间后再去⼲掉这个事务，或者在所有事务提交前，你先等待该事务执⾏
⼀⼩时再说
36:17 - 36:19
some systems do this
有些系统会这么做
36.19-36.20
, it is rare
但这很少⻅
36.20-36.23
it's most systems don't don't operate this way
⼤部分系统都不会使⽤这种⽅式
36:23 - 36:25
but you most system do shadow paging, all right
但⼤部分系统都使⽤shadow paging
36:27 - 36:29
IBM did this in system R in the 1970s
在1970年代的时候，IBM在System R中使⽤了Shadow paging
36:30 - 36:33
they abandoned it in the 1980s when they did DB2,
当他们在1980年代构建DB2的时候，弃⽤了这种⽅案
36.33-36.35
because you have fragmentation issues right
因为这存在着碎⽚问题
36:35 - 36:37
so now I blow a master page table
So，现在我⼲掉了这个master page table
36.37-36.39
I blow away these pages here
我也⼲掉了这些page
36.39-36.41
because they're no longer visible
因为它们不再可⽤
36:41 - 36:43
right so this is all that I have now
So，这就是我现在所有的page
36.43-36.46
but it doesn't match up the ordering of pages here
但磁盘上的这些page顺序与内存中这些page的顺序并不匹配
36:47 - 36:48
so now we do sequential scan
So，我们现在要进⾏循序扫描
36.48-36.50
you know I may not be reading things in the write order
你知道的，我可能并不是按照写⼊的顺序进⾏读取的
36.50-36.51
so I can't do clustering index
So，我没法使⽤聚簇索引（知秋注：聚簇索引所管理数据的pageid已经发⽣了变化，所以不可
⽤）
36.51-36.52
is what they were trying to do back in the day
这也是他们过去尝试做的事情
36:53 - 36:54
so nobody actually does this
So，实际没⼈这么做
36:55 - 36:56
but you absolutely right
但你说的绝对是对的
36.56-36.59
you're there you to commit him to bat or have one transaction from a time
你要去做批量提交，在⼀段时间内若有⼀个事务迟迟不结束，那就⼲掉它
36:59 - 36:59
yes
请讲
37:21 - 37:27
you know so you're going back to the previous table word t1 t2 ,would that handle in this
case yes
so 你要将这个table回到之前的状态，在这个case中就是对t1 t2进⾏处理
37:27 - 37:30
if you assume t1 t2 are committing together in the same batch
如果你假设T1和T2都是在同⼀批次中进⾏提交的话
37:31 - 37:39
right so yes ,t this is handled exactly in that case,
这就需要在这个case（例⼦）中对它们进⾏处理
37.34-37.39
because again I have the undo information I need to reverse any changes that a
transaction made in memory
因为在内存中我拥有我⽤来撤销事务所做修改时所需要的Undo信息
37:41 - 37:45
as long as that thing has been written out the disk
只要这些数据被写出到磁盘
37.45-37.48
, then I can just reverse it here
那么，我可以在shadow page table中撤销这些修改
37.48-37.49
and I'm fine
这就可以了
37:49 - 37:51
and if I crash before I flip the database root pointer
如果我在修改database root指针指向的东⻄之前崩溃了
37.51-37.52
then I'm fine
这也没啥
37:58 - 38:00
okay so nobody actually does this
Ok，实际上没⼈这么做
38.00-38.03
so let's jump through more quickly and get to the good stuff
So，我们快速过下这边的内容，然后去看些好东⻄
38:03 - 38:05
so the reason why this sucks
So，这种⽅案很操蛋的原因是
38.05-38.09
it because copying the entire page table is expensive
因为复制整个page table的成本太⾼
38.09-38.11
, you even if you use a tree structure
即便你使⽤的是树形结构
38.11-38.12
it becomes it's not cheap
复制它的成本也不会很低
38:13 - 38:14
and the committe overhead is high,
并且提交事务的开销很⾼
38.14-38.19
because you have to flush every single page that you modified ,the page table and the
root
因为你必须刷出你修改过的每个page，page table以及database root
38:20 - 38:21
the data becomes fragmented
数据就会变得很琐碎
38.21-38.24
you need a background garbage collector just like in a multi version concurrency control
你需要使⽤⼀个像多版本并发控制那样的后台垃圾回收器
38:24 - 38:28
and you either have to commit everything in a batch or only have one writer out of time
你可以⼀次性提交所有事务，也可以⼀次只提交⼀个事务
38:29 - 38:30
so as I said
So，正如我说的
38.30-38.35
the only systems I know that actually does do this or a CouchDB
我知道唯⼀这样做的系统就是CouchDB
38:35 - 38:38
but I think CouchDB is giving is going away from that
但我觉得CouchDB已经放弃了这种做法
38.38-38.41
and doing their switching over to RocksDB
它们现在切换到了RocksDB
38:42 - 38:44
LMDB is a tree based system
LMDB是⼀种基于树的系统
38.44-38.46
that uses mmap
它使⽤了mmap
38.46-38.48
so that's sort of hidden from them
So，这些都被它们隐藏了起来
38:48 - 38:51
and then against the system are in the 1970s
这些系统都是在1970年代推出的
38.51-38.53
that IBM abandoned that in 1980s
IBM在1980年代的时候废弃了它们
38:54 - 38:58
it one system you probably have heard about that does something similar to this as
SQLite
你们之前可能听过⼀个系统，它做的时候和这很相似，它就是SQLite
38:58 - 39:01
but this is what SQLite did up until 2010,
这就是SQLite在2010年之前的做法
39.01-39.06
then they dished it to and switched to over what we'll talk about next the write ahead
logging approach
然后，它们放弃了这种做法，并切换到我们接下来要讲的预写式⽇志这种⽅案
39:06 - 39:07
so what's SQLite would do is that
So，SQLite要做的事情是
39.07-39.18
instead of copying the page, that you would they're gonna modify and make a
modification in the copy
它们不会去复制它们要修改的page并在副本中进⾏修改
39:18 - 39:21
they have a copy original page, write that out the disk
它们会去复制⼀份page，并将它写出到磁盘
39.21-39.24
then make the modification to the master version
然后在master版本数据中进⾏修改
39:24 - 39:26
and then if you commit
接着，如果你提交事务
39.26-39.29
you just blow away the the copy that you had
你只需丢弃你所拥有的那个副本即可
39.29-39.30
or if you crash before you commit
或者，在你提交事务前，系统发⽣了崩溃
39:30 - 39:35
then you look back in that that separate copy file and restore the change
然后，你回过头去看这个单独的副本，并恢复该副本中的修改
39:36 - 39:38
so they would call this the Journal file
So，他们将这个叫做journal⽂件
39:38 - 39:41
so let's say that my transaction was a month update page two
So，假设我的事务⼀个⽉之前更新了page 2
39:41 - 39:43
so before I modify page 2 in memory
So，在我在内存中修改page 2之前
39.43-39.46
I first make a copy to it persist it on disk and a journal file
我⾸先会去制作page 2的副本，并持久化到磁盘中的journal⽂件中
39:47 - 39:48
and then when that's done
当这⼀步完成后
39.48-39.48
I can modify it
我就可以对内存中的page 2进⾏修改
39.48-39.50
,same thing with page 3
对于page 3也是如此
39.50-39.51
before I can modify it
在我可以修改这个page之前
39.51-39.53
I make a copy into separate journal file
我会制作该page的副本，并⽤⼀个单独的journal⽂件保存起来
39:54 - 39:56
then I go ahead and make my change
接着，我执⾏我的修改
39:56 - 39.56
now let's say
现在我们假设
39.56-39.58
before this transaction actually commits
在这个事务实际被提交之前
39.58-40.01
, we end up flushing out page 2 out the disk
我们会将page 2刷出到磁盘

20-03删图版
40:01 - 40:05
but before we flush out page 3 and actually commit this thing
但在我们刷出Page 3并提交该事务之前
40:06 - 40:07
we crash,
我们发⽣了崩溃
40.07-40.10
alright so everything gets blown away in memory
So，内存中的所有数据就灰⻜烟灭了
40:10 - 40:11
so when we come back
So，当我们想要恢复正常的时候
40.10-40.14
we would say alright well I have a journal file
我们表示，我有⼀个journal⽂件
40:14 - 40:19
so I need make sure that all my changes that are in this journal file because these the
original versions
So，我需要确保我所做的这些修改都在这个journal⽂件中，因为它们都是这些数据的原始版本
40:20 - 40:23
they get written out back to the the original disk file
它们会被写回原始的磁盘⽂件中
40:25 - 40:26
so again like I said
So，正如我说的
40.26-40.30
this is what this what SQLite did up till 2010
这是SQLite在2010年前所采⽤的⽅式
40:30 - 40:34
and then they abandon this for performance reasons to use to write ahead log
出于性能⽅⾯的原因，他们不再使⽤这种⽅法，⽽是改⽤了预写式⽇志
40:37 - 40:38
okay
40.38-40.433
so this shadow paging approach ,it'll guarantee correctness
So，这种shadow paging⽅案会为我们保证正确性
40:43 - 40:44
but it has some of some performance issues
但它存在着某些性能上的问题
40.44-40.47
and the main performance issue is going to be that
最主要的性能问题在于
40.47-40.51
it's we're gonna do a bunch of random I/O
我们会做⼤量的随机I/O
40:51 - 40:54
so back going back here in the SQLite example
So，回到这个SQLite的例⼦中
40:56 - 40.57
when I had to replay the journal file
当我需要重新执⾏这个journal⽂件中的操作时
当我需要重新将这个journal⽂件中的数据回归正轨
40.57-41.02
I'm updating random locations on disk to in order to restore the database back to the
correct state
为了让数据库回到正确的状态，我会去将pageid更新为这个磁盘中journal数据所在的随机位置
41:03 - 41:04
and here's a shadow paging
这⾥使⽤的是shadow paging
41.04-41.07
when I was flushing out all my changes and say my transaction actually committed
当我将我所有的修改刷出到磁盘，并表示我的事务实际已经提交了
41:08 - 41:14
again I'm doing random I/O to different locations to persist all the changes from the
shadow copy
我通过对不同位置进⾏随机I/O以此来持久化shadow副本中的所有修改
41:15 - 41:20
so even then with it fast SSDs that we had today
So，即便是使⽤我们当下速度很快的SSD
41:20 - 41:23
sequential I/O has always be faster than random I/O
循序I/O始终要⽐随机I/O来得更快
41:24 - 41:28
so we need way to convert all those random IOs into fast sequential I/O
So，我们需要某种⽅式将这些随机I/O都变成速度更快的循序I/O
41.28-41.33
and still have all the durability guarantees that we'd want in our logging protocol
并且我们依然想在我们的logging协议中做到持久化保证
41:34 - 41:38
so this is what write ahead logging is gonna achieve for us
So，这也就是预写式⽇志为我们所做的事情
41:39 - 41:41
so the idea was write ahead logs that
So，预写式⽇志的思路是
41.41-41.46！！！！
we're going to maintain a separate log file on non-volatile storage along with our table
heap
我们会在⾮易失性存储设备上维护⼀份单独的⽇志⽂件，以及我们的table heap
41:46 - 41:49
and as transactions make changes to the database
当事务对数据库进⾏了修改
41:49 - 41:54
we're gonna make entries into this log file that record the changes that were made
我们就会在该⽇志⽂件的条⽬中记录下这些修改
41:55 - 42:00
and then when a transaction go ahead and commit
当⼀个事务要提交的时候
42:00 - 42:04
we just need to guarantee that we flushed the log records that they generated out the
disk
我们仅需保证我们将它们所⽣成的⽇志记录落地到了磁盘上
42.04-42.10
and not the capital changes to the objects of the pages in the buffer pool
⽽不是将我们对buffer pool中page⾥⾯对象所做的修改落地到磁盘上
42:11 - 42:14
so for owner for us write ahead log in to say our transaction is committed and it's
durable
So，预写式⽇志表示，我们的事务已经被提交并落地了
42.14-42.16
we only need to flush the log
我们只需要将⽇志刷出即可
42.16-42.18
we don't need to flush anything else
我们不需要将其他东⻄刷出
42:18 - 42:21
and so now the log file is just sequential I/O
So，我们对⽇志⽂件做的就是循序I/O
42.21-42.23
because there's keep appending to this this file
因为我们⼀直在往该⽂件上追加记录
42.23-42.26
you know page after page of the page
你知道的，⼀个page接着⼀个page的追加
42:27 - 42:32
that again that's sequential I/O be much faster than the random I/O of of writing out the
the random pages
循序I/O的速度要⽐随机I/O往磁盘写出随机page的速度要快得多
42:33 - 42:35
and again the reason why it's call it write ahead log is
我们将其称为预写式⽇志的原因是
42.35-42.45
because we make sure that any log record that corresponds to a change made to an
object in the database is written a disk before that object can be written a disk
因为我们想确保当⼀个对象可以被写⼊到磁盘之前，我们对数据库中该对象所做修改对应的任何
⽇志记录都会先被写⼊到磁盘
42:47 - 42:51
so that's the very important most important thing to understand about write ahead
logging
So，这是预写式⽇志中你们所要理解的最为重要的⼀点
42:51 - 42:54
so write ahead logging at his example of steal and no force
So，预写式⽇志使⽤的是Steal+No-Force策略
42.54-43.01
because we're gonna be allowed to write dirty pages out the disk, before transactions
actually commit，as long as their log records have been written out first
因为在事务被实际提交前，只要这些事务所对应的⽇志记录先落地到磁盘，那么我们能够将这些
dirty page写出到磁盘
43:02 - 43:04
and then it's no force
接着，这⾥的策略是No-Force
43.04-43.07
because we don't require all the changes that the transaction made to objects we
written out the disk
因为我们不要求事务对这些对象所做的所有修改都落地到磁盘
43:08 - 43:10
we only require that the logrecords be written as a disk
我们只要求这些⽇志记录被写⼊到磁盘
43:12 - 43:17
so again this is the most important thing you need to understand in order to understand
the protocol
So，这是你需要理解的最为重要的⼀点，这样你才能理解这个协议
43:19 - 43:21
so the way anything about this is like
So，这其实就像是
43.21-43.24
if I have a transaction that updates a thousand tuples
假设我有⼀个事务，它要对1000个tuple进⾏更新
43:24 - 43:26
I potentially have to create a thousand log records
我可能就需要创建1000个tuple
43:27 - 43:31
so let's say that thousand tuples are stored in a thousand pages
So，假设这1000个tuple被保存在1000个page中
43.31-43.34
,my log records could just be stored in a single page
我的⽇志记录可能只需要保存在⼀个page中就⾏了
43:35 - 43:36
and therefore
因此
43.36-43.42
I'll need to want to do write one one page out to flush the log rather than all the pages
that they were modified
我只需要将保持着这些⽇志记录的page刷出到磁盘即可，⽽不是将所有被修改过的page刷出到
磁盘
43:42 - 43:45
so there's a bunch of performance advantages we're going to get from this approach
So，通过使⽤这种⽅案，在性能⽅⾯，我们会获得很多优势
43:47 - 43:52
so the DBMS is going to stage all the changes that a transaction makes in these log
records in volatile storage
So，DBMS会将⼀个事务所做的所有修改阶段性地保存在易失性存储中的这些⽇志记录中
43:53 - 43:55
this is typically also backed by the buffer pool
这些通常也会被buffer pool所备份
43:57 - 44:00
and then again this is we already talked about everything gets flushed out
我们已经讨论过所有东⻄都会被刷出
44:01 - 44:05
and they were not considered committed until we know that all our log records have
been written out to disk as well
直到我们所有的⽇志记录被落地到磁盘，我们才会去考虑事务提交
44:07 - 44:08
so the protocols don't work this way
So，协议在这⽅⾯并不奏效
44.08-44.09
so when our transaction starts
So，当我们的事务开启时
44:10 - 44:13
we have to write a begin record into our log
我们必须在我们的⽇志中写⼊⼀个BEGIN记录
44.13-44.18
that's gonna tell us that ,hey there's this transaction that started, it exists, here's some
metadata about it like
这会告诉我们，hey，这个事务开始执⾏了，这是关于该事务的⼀些元数据
44.18-44.19
here's the identifier for
这是它的标识符
44:20 - 44:21
and then when transaction commits
接着，当事务提交的时候
44.21-44.25！！！
we're gonna write a commit record out to the log
我们会往⽇志中写⼊⼀个COMMIT记录
44:25 - 44:34
and when you make sure that this commit record appears in the log after any log record
that corresponds to changes of that transaction made
你要确保该COMMIT记录出现在⽇志中的位置是在该事务所做修改的对应⽇志记录的最后
44:34 - 44:38
it's gonna be interleaved potentially with other changes that other transactions are
making
它可能会和其他事务所做的其他修改交织在⼀起
44:38 - 44:45
but for our one transaction that we care about at this point in time, our commit record
needs to appear after all its changes
但对于我们此时关⼼的这个事务来说，我们的COMMIT记录需要出现在该事务所做修改操作的
最后
44:45 - 44:48
I think they because once we see scenes come into log
因为我们⼀旦看到⽇志中出现这个COMMIT
44.48-44.50
we know there's no other change the transaction could ever make
我们就知道这个事务就⽆法再做其他修改了
44:52 - 44.54
so now in each log record
So，在每个⽇志记录中
44.54-45.00
first in the very you know it's an initial simplistic version of the protocol I'm teaching
right now
你知道的，我现在教你们的是该协议中最为基础的版本
45:00 - 45:02
we need to record four things
我们需要记录4个东⻄
45.02-45.05
the unique transaction identifier
事务的唯⼀标识符
45:05 - 45:09
right like the timestamp the transaction the sign when it was started
⽐如，事务开始执⾏时的时间戳
45:09 - 45:11
the object ID of the thing that actually modified
接着，实际被修改对象的Object ID
45.11-45.15
and then the before value with the corresponds to the undo
然后是Before value（该对象被修改前的值），这会在执⾏Undo的时候⽤到
45.15-45.17
and then the after value that corresponds to the redo
接着是After value（该对象被修改后的值），这会在执⾏Redo的时候⽤到
45:17 - 45:25
so this information by itself it's enough for us to be able that we need to in order to
recover the database, and for all possible failures that we talked about at the very
beginning
So，这些信息⾜以让我们能够恢复数据库，并处理我们在⼀开始所提到的各种可能故障
45:27 - 45:28
so let's look at an example here
So，我们来看个例⼦
45:29 - 45:30
so we just have t1
So，这⾥我们只有⼀个事务，那就是T1
45.30-45.31
there's a W(A) W(B)
它会先执⾏W(A)，再执⾏W(B)
45.31-45.33
,and so now in memory
So，现在在内存中
45.33-45.36
we have our write ahead log buffer as well as our buffer pool
我们有我们的WAL Buffer，以及我们的buffer pool
45:38 - 45:41
so when the transaction starts begin
So，当T1开始执⾏的时候
45:42 - 45:45 ！！
we're going to add an entry into our log record that says
我们会往我们的⽇志记录中添加⼀个新的条⽬，并表示
45.45-45.46
hey there's a transaction that just started
这⾥有⼀个刚开始执⾏的事务
45:48 - 45:50
it's usually not done exactly when you call begin
当你调⽤BEGIN的时候，通常该事务还并没有完成
45.50-45.55
it's usually done unless you're running with auto commit turned on
除⾮你调⽤COMMIT，该事务才会完成
通常只有在事务结束的时候
45:55 - 45:56
it's usually done at the first write
通常它在第⼀个写操作的时候，就完成了(知秋注:说明预写⽇志落地了)
45:57 - 45:59
but different systems can do different things
但不同的系统做法也不⼀样
45:59 - 46:01
so now I do W(A)
So，现在我执⾏W(A)
46.01-46.04
so the first thing I need to do is add our entry to my log buffer,
So，我⾸先需要做的事情就是往我的WAL Buffer中添加条⽬
46.04-46.07
that says here's the change I'm making to a
该条⽬表示，这是我对A所做的修改
46:07 - 46:10
right here's the before value, and here's the after value
这⾥是Before Value，那⾥是After Value
46:11 - 46:13
and once that's in my log buffer
⼀旦这条记录出现在我的WAL Buffer中
46.13-46.19
now I go ahead and make my change into my page in my buffer pool
我就会对我buffer pool中的page进⾏修改
46:19 - 46:19
all right
46.19-46.21
we'll talk about this more that next class
我们会在下节课讨论更多关于这⽅⾯的问题
46.21-46.23
the reason why you have to do this before this
我们先将⽇志写⼊WAL Buffer⽽不是先修改buffer pool中page数据的原因是
46:23 - 46:26
because there's gonna be this thing called a log sequence number
因为这⾥⾯有⼀个叫做⽇志序列号的东⻄
46.26-46.28
that's gonna get assigned to the log record
我们会将它分配给⽇志记录
46.28-46.35
that we had to use to figure out what's the log entry that changed this particular page
我们需要通过⽇志序列号来弄清楚是哪个⽇志条⽬对这个page进⾏了修改
46:35 - 46:37
so you may think who cares into the muttering out the disk
So，你们可能会想谁会在意这是否会弄乱磁盘上的数据呢
46.37-46.40
can I just update this first then add this thing in here
我是否能先更新buffer pool中的数据，再将对应记录添加到WAL Buffer中
46:41 - 46:45
we'll see next class why you have to do this first followed by this
我们会在下节课中看到，为什么我们要先往WAL Buffer中写⼊⽇志记录，紧接着再去修改
buffer pool中的数据
46:47 - 46:49
so then now I do the W(B) same thing
So，接着，当我执⾏W(B)的时候，我也会经历相同的流程
46.49-46.53
I add my entry to my write ahead log buffer in memory,
我会往我的WAL Buffer中添加我的⽇志条⽬
46.53-46.55
then I go ahead and make my change here
接着，我会在buffer pool中进⾏我的修改
46:55 - 46.57
so now when I go ahead and do a commit
So，当我进⾏提交的时候
46.57-47.01
I add my commit record to my write ahead log buffer
我会将我的COMMIT记录添加到WAL Buffer中
47:01 - 47:02
then at some point
接着，在某⼀时刻
47.02-47.05
I'm gonna flush it out the disk
我会将WAL Buffer中的⽇志记录落地到磁盘
47.05-47.05
in this case here
在这个例⼦中
47.05-47.07
since we need to tell the outside world that a transaction is committed
因为我们需要告诉外界这个事务已经被提交了
47.07-47.10
will immediately flush this out do an F sync
我们会⽴即调⽤FSync命令将这份⽇志刷出
47:10 - 47:13
once we know that's durable and say from disk
⼀旦磁盘告诉我们，该⽇志已经被持久化了
47.13-47.13
at this point
此时
47.13-47.18
the transaction is considered safe to now return back the application and say that it's
committed
该事务就会被认为是安全的，我们会告诉应⽤程序该事务已经被提交了
47:19 - 47:23
so now who cares that Hitler comes along and kills shows our buffer pool
So，现在也就没⼈在意闪电⻛暴之类的东⻄⼲掉我们buffer pool中的数据了
47:24 - 47:28
because everything we need to do to replay the changes that it made is now safe on
disk
因为重新执⾏这些修改操作所需的⼀切信息都已经安全落地到磁盘了
47:29 - 47:32
so if this page number got written out
So，如果这个保存着⽇志记录的page落地到了磁盘
47.32-47.38
we can just look in that log and replay it to update the page as needed
通过查看这份⽇志，我们就可以根据需要重新执⾏对该page所做的更新
47.38-47.44
to do exactly the same thing the transaction did when it ran the first time
以此来做到和该事务第⼀次执⾏时完全相同的效果
47:44 - 47:46
so again at a high level is this clear
从⾼级层⾯来看，你们懂了吗？
47:48 - 47:48
yes
请问
47:54 - 47.54
our question is
我们的问题是
47.54-48.03
what is instead of storing the write ahead log buffer as a separate file what if I stored it
in the page itself
为什么我将WAL Buffer中的数据保存在某个page内，⽽不是将它作为⼀个单独的⽂件保存呢
48:12 - 48:14
I said you told me like Oh Sorry a log structure storage we talked about earlier
Oh，抱歉，你说的是不是我们很久以前讨论过的log-structured Storage
48:15 - 48:16
yeah so in the log structure storage
So，在Log-Structured Storage中
48.16-48.21
you don't have this on disk
你磁盘中并没有这种page
48.21-48.22
you only have this
你磁盘中存放的都是这种⽇志
48:26 - 48:29
yeah it's a log structured correct
没错，这就是log structured Storage
48:29 - 48:38
what you're giving up by hat not having this,is that reads are now more expensive
如果你不使⽤这种⽅案（放弃使⽤page），那么，这会让你的读操作成本变得很⾼
48.38-48.42
because you have to replay the log to figure out what the page I should look like when
every read
因为当每次读取数据的时候，你必须重新执⾏⽇志上的这些内容，以弄清楚我应该读取哪个
page
48:43 - 48:45
but it makes some write super fast,
但这会让写操作的速度变得⾮常快
48.45-48.47
now you don't do extra writes to write out dirty pages
你不需要做额外的写操作来将这些dirty page写出到磁盘
48.47-48.49
you only keep appending things to the log
你只需要追加⽇志条⽬即可
48:50 - 48:51
so there's a trade-off
So，这就是种取舍
48.51-48.59
so this will be like RocksDB ,levelDB, Cassandra ,bunch of systems do these log
structures storage
So，诸如RocksDB、LevelDB、Cassandra之类的系统使⽤的都是这种log-structured Storage
49:00 - 49:01
yeah for us
对于我们来说
49.01-49.03
I here assume you have table heaps
假设我们这⾥有table heap
49.03-49.06
we write everything we talked about we have table heaps we have write ahead log
我们有table heap，我们使⽤了预写式⽇志
49:06 - 49:08
we're not doing the log structure stuff we talked about before
我们并没有使⽤我们之前讨论的log structured Storage之类的东⻄
49:08 - 49:10
but the concept is still the same,
但理念依然是相同的
49.10-49.13
you just don't have this ,you don't have a table heap
在log structured Storage中，你只是没有这些page，也没有这些table heap
49:24 - 49:25
so his question is
So，他的问题是
49.25-49.26
if I have 2 transactions
如果我有2个事务
49.26-49.29
and they're updating the database
它们要对数据库进⾏更新操作
49.29-49.33
are there log records and are mixed in the same log buffer or they have separate log
buffers
这些⽇志记录是放在同⼀个WAL buffer中的，还是使⽤不同的WAL buffer来分别保存这些⽇志
记录
49.33-49.34
they're intermixed
它们是混在⼀起的
49:35 - 49:39
again this is independent orthogonal to the commercial stuff
这和商⽤数据库是不同的
49:39 - 49:46
so some higher-level part of the system that determines whether one transactions
allowed to update, you know what we know this object or that object
So，有些⾼级系统会去决定某个事务是否允许去更新这个对象或者另⼀个对象
49:47 - 49:48
at this point
此时
49.48-49.50
we assume that they're allowed to do that
假设我们允许它们这样做
49.50-49.52
and they did do that they're going to do it
并且它们也会这样做
49.52-49.56
and therefore we just add their log records into the log file
因此，我们只需将它们的⽇志记录添加到⽇志⽂件中
49:56 - 49:59
we don't maintain several log files for different transactions
我们不会为不同的事务去维护多份⽇志⽂件
50:01 - 50:04
because we have a transaction B, we know who did what ,yes
因为我们知道事务B是谁执⾏的，确实如此
50:08 - 50:08
okay
50:09 - 50:11
so again if we crash
So，如果我们遇上了崩溃
50.11-50.16
there's everything we need to restore the database is in the log
我们需要⽤来恢复数据库的⼀切东⻄都放在了⽇志中
50:16 - 50:19
so to sort of implementation questions
So，我们来讲下实现⽅⾯的问题
50:20 - 50:20
one is
其中⼀个问题是
50.20-50.23
when should the database assumed write out the log entries to disk
DBMS何时应当将⽇志条⽬落地到磁盘
50:23 - 50:25
well the talks as we said
Well，我们之前讲过
50.25-50.31
it's whenever the transaction commits, before we tell the outside world our transactions
going to go ahead you know is fully committed
即当事务提交的时候，在我们告诉外界我们的事务被完全提交的时候
50:31 - 50:35
we do make sure that those log records and the buffer are now stored out at on disk
我们会确保这些⽇志记录和buffer已经被保存到磁盘上了
50:35 - 50:37
that's all we need to be able to restore the database
这些就是我们所需要能够⽤来恢复数据库的东⻄
50:39 - 50:40
but my example here
但在我的这个例⼦中
50.40-50.41
I only showed one transaction
我只展示了⼀个事务的例⼦
50:43 - 50:44
and when they said commit
当事务要提交的时候
50.44-50.46
you know I just mean did F sync and write it out
我的意思是调⽤FSync将数据写出到磁盘的时候
50:47 - 50:54
but that's actually gonna be super slow, if for every single transaction I do an Fsync
when they commit to write out it's a log buffer
但这样做实际上速度很慢
但如果我提交每个事务的时候都调⽤FSync来将数据写出到磁盘，这样做实际上速度很慢
50:54 - 50.56
that's not what I'm gonna want to do,
这不是我想要做的事情
50.56-51.00
because saying Fsync takes five milliseconds on a slower disk
假设，在⼀个速度较慢的磁盘上执⾏FSync需要花5毫秒
51:00 - 51:02
then I can only commit one transaction every five milliseconds
那么每5毫秒我只能提交⼀个事务
51.02-51.06
that's gonna be bad
那这样就会很糟糕
51.06-51.08
I can only do two thousand transactions a second
我⼀秒钟就只能执⾏2000个事务
51:09 - 51:13
so every system actually implements instead is what's called group commit
So，相反，实际上，所有系统都实现了⼀个叫做group commit（组提交）的东⻄
51.13-51.19
where you're gonna allow multiple transaction to buffer up a bunch of changes in the log
buffer
即你允许多个事务将它们的⼀系列修改都积累在log buffer中
51:19 - 51:20
and then at some point
接着，在某个时间点
51.20-51.21
you make a decision
你做出了决定
51.21-51.23
all right now I'm gonna go ahead and write whatever's in the log buffer out the disk
现在，我要将log buffer中的内容写出到磁盘
51:24 - 51:27
and then may include log records from transactions that have not commit yeah
这样做的话，这⾥⾯可能包含了那些未提交事务的⽇志条⽬
51:28 - 51:29
but that's fine
但这没关系
51.29-51.32
because we know how to undo their changes
因为我们知道该如何撤销它们所做的修改
51.32-51.34
because we have the undo information in the log record
因为我们的⽇志记录中保存了这些Undo信息
51:35 - 51:38
so this is what you're going to end up happening implement in in project 4
So，这就是你们最终要在Project 4中所实现的东⻄
51:38 - 51:41
so the way it basically works is that
So，简单来讲，它的⼯作⽅式是
51.41-51.45
in the simple form you instead of having one log buffer, you have 2 log buffers
在这种简单的形式中，你会有2个log buffer，⽽不是1个
51:45 - 51:46
it's sort of like shadow paging,
这有点像shadow paging
51.46-51.47
there's the master
这就像是shadow paging中的master
51.47-51.49
when everyone's writing to ,
所有⼈都会先往master中写⼊数据
51.49-51.52
and there's the background one that you're eventually write to next
当master中写满数据后，你会往后台这个buffer中写⼊数据
51:53 - 51.56
so when my transaction starts t1 here does W(A)
So，当T1开始执⾏W(A)
51.56-52.02
you always go to the first one first add the begin
你始终会先跑到第⼀个WAL buffer中，并添加BEGIN记录
52.02-52.04
then do the W(A) to W(B)
然后执⾏W(A)和W(B)
52:04 - 52:06
now I do a context switch here
现在，我进⾏上下⽂切换到T2
52.06-52.07
all right
52.07-52.08
at T2's entry
在T2的条⽬中
52.08-52.10
go write on C
它会执⾏W(C)
52:10 - 52:13
but now at this point my log buffer is full
但此时我第⼀个WAL buffer满了
52:14 - 52:16
so I can't add anything else in here
So，我没法往这⾥添加其他任何东⻄
52:17 - 52:21
so I'm gonna go ahead and write this out the disk
So，我会将这个WAL buffer中的东⻄写出到磁盘
52:22 - 52:22
all right
52.22-52.24
and I have to do Fsync
我需要去调⽤FSync
52.24-52.25
,so that you know that's gonna take some time
So，你知道的，这样做需要花点时间(知秋注:背后隐含了⼀个锁同步)
52:25 - 52:27
so in the meantime now
So，与此同时
52.27-52.29
,I switch over to my second log buffer
我就会切换到我的第⼆个WAL buffer
52:29 - 52:33
and now any other changes that transactions may get added to this thing here
现在，事务所做的其他修改可能就会添加到这个WAL buffer中
52:34 - 52:36
the idea is
这⾥的思路是
52.36-52.37
start your wild ones getting read out in a disk
在⼀个buffer要去写出磁盘的
52.37
,you fill up the next one
你就可以往下⼀个⾥填充数据
52.38-52.38
when that gets filled
当它被填满时
52.38-52.41
,then ideally the other ones been flushed out
那么，理想情况下，另⼀个WAL buffer已经被刷出到磁盘
52:41 - 52:44
so now then you write the second one out
So，然后，你再将第⼆个WAL buffer刷出到磁盘
52.44-52.44
,and then fill up the first one
接着，再往第⼀个WAL buffer⾥⾯填充数据
52.44-52.46
so just going back and forth
So，我们只需这样反复操作即可
52.46-52.49
while ones getting flushed，you fill up the other one
当⼀个WAL buffer中的数据被刷出到磁盘时，我们就去往另⼀个WAL buffer中填充数据
52:51 - 52:54
but let's say for this transaction here
我们来看下这⾥的事务
52.54-52.55
it stalls
它停滞住了
52.55-52.56
right it does something
这⾥它在做某些事情
52.56-52.58
right it does additional computation
它做了些额外的计算(知秋注:在做写操作时，其中包含了⼀些计算，有锁在独占资源)
52:58 - 53:01
so neither transaction are generating new log records
So，不管哪个事务都不会⽣成新的⽇志记录
53:02 - 53:06 ！！！！！
so instead of just waiting till it's filled up before I write it out
so，与其等到写满之前再写出
53:06 - 53:10
there's also a second process where you you say
这⾥还会有第⼆个步骤
53.10-53.12
well if it's been a certain amount of time ，since I've last flushed this thing out ,let me
go ahead and flush it out
在上⼀次数据刷出到磁盘之后，过了⼀定的时间，此时wal buffer 并没有满，我们依然将buffer
内的数据刷出到磁盘
53:18 - 53:19
and the idea is
这⾥的思路是
53.19-53.20
you should want to tune it such a way that
你想以某种⽅式对其进⾏调优
53.20-53.23
like if you know that what the fsync time is write something up the disk
⽐如，如果你知道你调⽤FSync将数据写出到磁盘的耗时是多少
53.23-53.26
then you sort of set your timeout to be that
那么，你就可以将你的超时时间设置为这个值
53:26 - 53:32
so like if it takes me five milliseconds to write the first page out or the first log buffer
So，如果我要花5毫秒将第⼀个page或者第⼀个log buffer写出到磁盘
53:32 - 53:35
then I'll wait five milliseconds for the second one
那么，我要等5毫秒才能将第⼆个page写出到磁盘
53.35-53.36
and when what five milliseconds is up
当5毫秒到了
53.36-53.39
if I'm not full yet I go ahead and write that out as well
如果这个page并没有满，我就会将这个page写出
53:42 - 53:44
so again group commit basically says
So，简单来讲，group commit指的是
53.44-53.48
instead of one transaction Fsync the log, when it commits
当事务提交的时候，我们不会去调⽤Fsync来将该⽇志写出到磁盘
53:48 - 53:50
you back to bunch of them together
⽽是将这些事务积累在⼀起
53.50-53.32
and then you amortize the Fsync costs across multiple transactions
然后，我们再对多个事务⼀起调⽤FSync
53:53 - 53:56
so if you're the first transaction that gets added to the log buffer
So，如果你是log buffer中被添加的第⼀个事务
53:56 - 53.57
and then you commit
接着，你提交了该事务
53.57-53.59
you're kind of like you're screwed
接着，你搞砸了
53.59-54.02
,because you have to wait the longest before you're actually written out the disk
因为在你将数据写出到磁盘前，你必须等到间隔超时才⾏
54:02 - 54:03
but if you're the last guy
但如果你的事务是这⾥⾯最后⼀个事务
54.03-54.07
then it's as if you get that you're getting the disk exactly to yourself,
完全可以随你⼼意做你想做的事情，将⽇志刷出到磁盘
54.07-54.08
because you're not waiting any time
因为你⽆须等待
54:08 - 54:09
so on average
So，从平均⻆度⽽⾔
54.09-54.12
this works out to be much better than everyone Fsync immediately
这要⽐每次⽴即调⽤FSync来得更好
54:16 - 54:17
all right
54.17-54.19
so then the the last question is
So，最后⼀个问题是
54.19-54.21
when should be actually write the dirty records out to disk
DBMS应该在什么时候将这些dirty record写出到磁盘
54:22 - 54:24
well this depends now
Well，这取决于不同情况
54:26 - 54:28
so now that we said
So，我们说过
54.28-54.36！！！！！
that the log buffers everything we need to do everything all the operations we need to be
able to redo the changes that transaction is made
对于这个log buffer，我们需要能够去redo⼀个事务所做的所有修改
54:36 - 54:42
and we say that the log records that correspond to changes to pages are written out to
disk before this page is written out to disk
我们有说，在这个page写出到磁盘前，这些修改对应的log 记录应该写出到磁盘
54:43 - 54:50
it's not actually immediately urgent for us to flush all those pages immediately when the
transaction commits, until the log records have been flushed
当该事务提交时，这些page代表的修改并不会⽴⻢刷出到磁盘，直到⽇志记录已经被刷出到磁
盘为⽌
54:51 - 54:54
so now on our replacement policy in our buffer pool manager ,we can account for this
现在在我们的buffer pool manager中执⾏替换策略，我来解释下
54:54 - 55:02
we can say all right well this thing is Dirty, but I the log records been written out for it
,so maybe I don't want to evict this one right away
我们有看到这个page是dirty，但它对应的 log records已经被写出到磁盘了，可能我并不想要⽴
⻢将这个dirty page刷出去的
55:02 - 55:11
right can evict it right away ,where this other one here, although it's probably as a higher
priority for me getting removed or getting evicted, its log records haven't haven't been
flushed yet
这个page⾥还有另⼀个，尽管它可能相对于我来讲有更⾼的优先级去刷出去，但它的log
records 还未刷出去
55:12 - 55:16
so maybe I don't want to dick that one, because I have flush the buffer first before I can
write that out
so 我不想去管之前那个，因为我要在它之前先把优先级⾼的这个刷出去
55:19 - 55:23
so this idea of log and recovery permeates throughout the entire system
So，这种log和recovery的思想遍布整个系统
55:23 - 55:29
and now we need to account for the other parts of the system ,but we've already talked
about, we can update replacement policy to keep track of these things
我们需要考虑系统的其他部分，但是我们已经讨论过了，我们可以更新替换策略来跟踪这些情况
55:29 - 55:29
yes
请讲
55:42 - 55:42
all right
55.42-55.44
so so this question is
So，他的问题是
55.44-55.45
well in these example
Well，在这些例⼦中
55.45-55.46
we don't recommit
我们没有重新提交
55.46-55.47
so let's say that
So，假设
55.47-55.49
I have committed a log buffer
我已经提交了⼀个log buffer
55:50 - 55:54
but before I read up at this on a crash, who cares
但在我读取这个的时候，发⽣了⼀个崩溃事件，管它呢，崩就崩咯
55:55 - 55:58
ah no no the application said commit
No No，应⽤程序表示它提交了这个事务
56:00 - 56:01
we haven't told me you committed yet,
我们还未告诉你这个事务已经被提交了
56.01-56.07
we only tell them that they commit, when that log buffer that corresponds that commit
message is written to disk
只有当log buffer中与该事务相关的COMMIT消息被写⼊到磁盘后，我们才会告诉外界我们提交
了这个事务
56.07-56.09
that's the genius of this
这就是它的天才之处
56:09 - 56:13
Right, because again the the if we're doing OCC
如果我们使⽤的是OCC
56.13-5.16
where we're doing validation after the transaction commits
当我们提交完事务后，我们还要进⾏验证操作
56:16 - 56:19
we still might end up getting aborted
最终我们得到的结果可能依然是中⽌该事务
56:19 - 56:21
right at this point here at the log buffer
在log buffer这⾥
56.21-56.23
we assumed all that's taken care of
我们假设这⾥的事务都执⾏完毕
56:23 - 56:24
so we see a commit message here
So，在这⾥我们看到了⼀条COMMIT消息
56.24-56.35
, we don't tell you know there's you know callback to say, yeah you're good everything's
durable until the log buffers we've written a disk
直到我们将log buffer写⼊到磁盘后，这⾥的回调函数才会告诉我们这些东⻄都被持久化了
56:35 - 56:36
his question is
他的问题是
56.36-56.38
is the application hanging for a while
应⽤程序是否会中⽌⼀段时间
56.38-56.39
,yes
没错
56:41 - 56:41
Correct
说的没错
56.41-56.43
but I mean like
但我的意思是
56.43-56.44
what else would you do
你还能做哪些其他事情？
56.44-56.48
,otherwise if you don't want to wait to see what you committed,
否则，如果你不想等待看到你所提交的内容
56.48-56.48
that's fine
这也没关系
56.48-56.49
but you could lose data
但你可能会丢失数据
56:50 - 56:55
right so if I don't run it a transaction
so 如果你不想在事务中做这个事情（也就是如果你不想等待看到你所提交的内容）
56.53-56.55
then then you know
那么你就会知道
56:57 - 57:00
actually even even if you do auto commit here's a single state by transaction
实际上，如果你做了⾃动提交（auto commit），这⾥对于事务来讲，会有⼀个单独的状态
57:01 - 57:05
I think it's still gonna write a log record before it comes back and says your things
actually finished
我觉得在系统实际告诉你它执⾏完这些事务前，它依然会去记录下⽇志记录
57:06 - 57:13
some systems allow you to turn off logging on a per transaction basis
某些系统允许你关闭每个事务的logging功能
57:13 - 57:14
so I can run a transaction
So，我可以执⾏⼀个事务
57.14-57.16
that would say
并表示
57.16-57.19
, I make a bunch of changes
我做了很多修改
57.19-57.20
but when I commit
但当我提交的时候
57.20-57.22
don't write anything out the log
我不会往⽇志中写⼊任何东⻄
57:23 - 57:24
you could do that,
你可以这么做
57.24-57.26
some systems will allow to do that
有些系统允许这么做
57.26-57.27
,by default they don't
默认情况下，它们不会这么做
57:29 - 57:29
yes
请讲
57:33 - 57:35
do we need to commit entries about read-only transaction
我们是否需要提交与只读事务相关的⽇志条⽬？
57:36 - 57:40
or we don't
57.35-57.38
his question is
他的问题是
57.38-57.40
do we need to commit entries for read-only transaction
我们是否需要提交只读事务的相关⽇志条⽬
57:40 - 57:41
what do you think
你是怎么想的呢？
57.41-57.43
,well what would you have to commit
Well，哪些东⻄是你必须要提交的
57:46 - 57:48
what would the log record be
要提交的⽇志记录是什么？
57:49 - 57:51
there's nothing to log
这⾥没有什么可记录到⽇志中的
57.51-57.53
, this is what I'm saying like going back here ,uh oh sorry
这就是我说的，我们先回到这⾥，不好意思，按错了
57:57 - 57:58
guy Taemin hmm
该死
57:59 - 58:01
Oh that wasn't me that was PowerPoint
这是PowerPoint的错
58:05 - 58:05
sorry
抱歉
58:06 - 58:08
so I showed the
58:13 - 58:15
right and this in this case here
在这个例⼦中
58.15-58.18
, I showed that when the transaction started I had to begin entry
当事务开始执⾏的时候，我必须写⼀个BGEIN条⽬到我的WAL Buffer中
58.18-58.21
you don't have to do that
你⽆须这么做
58:21 - 58:23
right because if it's a read-only transaction
因为如果它是⼀个只读事务
58.23-58.25
like if this thing called begin
如果这⾥调⽤了BEGIN
58.25-58.27
but then did a bunch of reads
接着，它进⾏了⼀系列读操作
58.27-58.29
then I'm storing crap that I don't care about
那么，我就会保存⼀些我不关⼼的废话
58:30 - 58:32
you could do that you don't have to though
你可以这么做，但你不⼀定要去做
58:33 - 58:33
Right
58.33-58.34
in some systems
在某些系统中
57.34-58.37
you can actually declare a transaction read-only at the beginning
实际上，你可以在⼀开始的时候就声明这个事务是个只读事务
58:37 - 58:40
that you say begin as read-only or something in SQL
你可以在SQL中声明该事务是⼀个只读事务
58:40 - 58:47
then you just turn off all logging and all concurrency control, if you're doing snapshot
isolation,
如果你正在进⾏snapshot isolation，那么你就会关闭所有logging和并发控制相关的功能
58.44-58.47
because you just know that I'm gonna see exactly what I should be seen
因为我会看到我应该看到的东⻄
58:50 - 58:51
for simplicity's I'm showing that here
出于⽅便起⻅，我这⾥将它展示了出来
58:52 - 58:52
yes
请问
58:56 - 58:56
so question is
So，问题是
58.56-58.58
when you garbage like the logs
当你对这些⽇志进⾏垃圾回收的时候，这会发⽣什么
58:58 - 59:00
a few more slides will get there yes
我们会通过⼀些幻灯⽚来展示这个
59:01 - 59:05
actually is spoilers checkpointing
实际上，我们在讲checkpoint的时候会讲到这
59:06 - 59:06
but we'll get to that
但我们会提到这个
59:07 - 59:07
okay
59:09 - 59:11
so just to recap everything we talked about
So，这⾥重述下我们已经讨论过的东⻄
59:12 - 59:16
the way it is heard a thing about the different methods for doing buffer pool
management and recovery
我们讨论了⽤于处理buffer pool管理和数据库恢复的不同⽅法
59.16-59.21
is in the context of the runtime performance and the recovery performance
这与Runtime性能和Recovery性能有关
59:22 - 59:28
so the runtime performance would be how fast is it for you know to maintain all this
information while I run transactions
So，Runtime性能指的是，当我执⾏事务的时候，它维护所有信息的速度有多快
59:28 - 59:30
so in the case of No-Force+Steal
So，在No-Force+Steal的情况下
59.30-59.33
which is write ahead logging that's gonna be the fastest during run time
它使⽤的是预写式⽇志，它的运⾏时性能是最好的
59:33 - 59:35
because when I commit
因为当我提交的时候
59.35-59.37
I'm just committing out those log records
我只需提交这些⽇志记录
59.37-59.37
I don't worry about those dirty pages hanging my buffer pool
我不⽤考虑我buffer pool中的那些dirty page
59:39 - 59:41
I'll take care of them at some later point
我之后再去处理它们
59:42 - 59:43
whereas with shadow paging
当然，当使⽤shadow paging的时候
59.43-59.43
it's more expensive
它的成本就会更加昂贵
59.43-59.48
because I have to make sure I flush all the page that I modified and my shadow page
table
因为我必须确保我将所有修改过的page和shadow page table都刷出去了
59:48 - 59:52
then flush the database root to disk before I can tell the outside world I commit
在我可以告诉外界我提交了该事务前，我要将database root也刷出到磁盘
59:53 - 59:55
but now the downside is
但现在的缺点是
59.55-59.57
if I have to recover the database after a crash
如果我经历崩溃后需要恢复数据库
59.57-59.59
,shadow paging is the fastest
那么，shadow paging的速度是最快的

20-04
59:58 - 01:00:00
because I don't do anything extra
因为我并没有做更多事情
1.00.00-1.00.05
I just come back and my DBMS root points to my shadow page or the consistent master
我的database root指向的是我的shadow page或者master
01:00:05 - 01:00:07
the most recently committed version
即那个最近提交的版本
1.00.07-1.00.08
and I'm done
这样我就完事了
01:00:08 - 01:00:10
but under write ahead logging
但如果使⽤的是预写式⽇志
1.00.10-1.00.11
that's actually slower
实际上，它的速度更慢
1.00.11-1.00.15
because I have to replay the log up to some some point
因为我需要重新执⾏⽇志中的操作，并执⾏到⽇志中的某个点为⽌
01:00:15 - 01:00:18
which she was sort of alluding to with garbage collection
这和垃圾回收有点相关联
01:00:19 - 01:00:23
so because of this trade-off between performance and recovery time
So，因为性能和恢复时间上的这种权衡关系
01:00:24 - 01:00:29
most database system implementations, choose the the write ahead logging, choose the
No-Force+steal
⼤部分数据库系统选择去实现的是预写式⽇志，采⽤的策略是Np-Force+Steal
01:00:29 - 01:00:31
because they'd rather be faster at runtime
因为它们更希望在运⾏时速度更快
1.00.31-1.0034
and assume failures are gonna be rare
并假设出现故障的频率⾮常稀少
1.00.34-1.00.37
which you know in the grand scheme of things they are
01:00:37 - 01:00:41
your DBMS not crashing every minute if you do， we have other Problems
你的DBMS不会每分钟都发⽣崩溃，如果你遇上这种情况，说明我们遇上了其他问题
01:00:41 - 01:00:42
so therefore
因此
1.00.42-1.00.46
they're willing to trade off faster runtime performance in exchange for slower recovery
他们更希望⽤较快的运⾏时性能来交换更慢的恢复速度
01:00:48 - 01:00:56
there's only one system that I'm aware of except for the ones that do shadow paging like
the old SQLite
除了⽼版的SQLite会使⽤shadow paging以外
01:00:56 - 01:01:03
there's only one system that I can make the trade-off for having faster recovery time in
exchange for running slower at runtime
01:01:04 - 01:01:06
and it was this system I don't know the name of it
我不记得这个系统的名字叫什么
1.01.06-1.01.12
,it was a database system built in the 1970s for the Puerto Rico’s electrical system
这个数据库系统是在1970年代为Puerto Rico电⼒系统所构建的
01:01:12 - 01:01:15
because in Puerto Rico in the 1970s they had power outages like every hour
因为在1970年代，Puerto Rice每⼩时都会遇上停电的情况
01:01:15 - 01:01:18
so the DBMS was crashing literally every single hour
So，他们的DBMS每⼩时都会遇上故障
01:01:18 - 01:01:19
so for them
So，对于他们来说
1.01.19-.01.21
it was much better to be slow at runtime
运⾏时的速度慢点会更好
1.01.21-1.01.24
such that for every hour ,when you crashed ,when you lose power
这样的话，当每⼩时你断电的时候
01:01:25 - 01:01:27
you could recover the database immediately afterwards
你就可以⽴即恢复你的数据库
01:01:29 - 01:01:33
right another were there anything like this at the high level to is
另⼀个⾼级层⾯的东⻄就是
1.01.33-1.01.34
this is with no undo no redo
这⾥没有Undo，也没有Redo
1.01.34-1.01.35
because there's nothing to reverse
因为这⾥没有东⻄要恢复
1.01.35-1.01.37
and nothing to reapply
也没有东⻄要重新提交
1.01.37-1.01.39
with write ahead logging，you need undo and redo
如果使⽤的是预写式⽇志，那你就需要Undo和Redo
01:01:42 - 01:0143
all right
1.01.43-1.01.47
so at a high level what these log records are
So，从⼀个⾼级层⾯来看，这些⽇志记录是什么样⼦呢
1.01.47-1.01.49
that there's an object ID
这⾥⾯有⼀个Object ID
1.01.49-1.01.52
and then there's a before value and the after value
这⾥⾯有⼀个before value，以及⼀个after value
01:01:53 - 01:01:55
but what how this is actually implemented
但这实际是如何实现的呢
01:01:56 - 01:01:57
so there's a couple different approaches
So，这⾥有两种不同的⽅案
01:01:58 - 01:02:01
so the one would be what it's called physical logging
So，其中⼀种⽅案叫做Physical Logging
1.02.01-1.02.03
which is basically what I've talked about so far
基本上来讲，这也是我⽬前所讨论的东⻄
01:02:04 - 01:02:13
its we're recording the low level byte changes to a specific location as some object in
the database that you made to and you know how to reverse it
我们会去记录你对数据库中某个特定位置所做的低级层⾯的字节修改，并且你知道如何撤销你的
修改
01:02:13 - 01:02:15
so thinking this is like if you run diff or git diff
So，你们可以去思考下git diff
01:02:16 - 01:02:21
it's but allows you to get out the before and after of the change
这使得你可以获取修改前后的数据
01:02:22 - 01:02:23
but the downside of this is again
但它的缺点在于
1.02.23-1.02.27
if I update of you know billion tuples in my transaction
如果我在我的事务中要更新10亿条tuple
01:02:28 - 01:02:32
I have to have a billion log records that corresponds to all those low-level physical
changes
那么，我就需要使⽤10亿条与这些低级层⾯物理修改所对应的⽇志记录
01:02:34 - 01:02:36
another approach is do logical logging
另⼀种⽅案就是使⽤Logical Logging
1.02.36-1.02.41
where you just record the high-level operation that which of the change you made to the
database
即你只记录那些你对数据库所做的⾼级层⾯的修改
01:02:42 - 01:02:46
and that's enough for you to be able to reapply it at run time
这⾜以让你在运⾏时重新执⾏这些操作
01:02:46 - 01:02:48
undo is a lot more tricky
Undo的话，则更为棘⼿
1.02.48-1.02.52
based if you have you know based on what the actual query is
这取决于实际的查询是什么
1.02.52-1.02.52
but let's ignore that for now
但我们现在将它忽略
01:02:54 - 01:03:00
so I think the way thing like this is this is storing like in the diff of the change you made
So，这其实就是去保存你对数据修改前后的不同之处
01:03:00 - 01:03:04
this is storing actually the SQL query that of the change you made
实际上，这保存的是你在执⾏SQL查询时所做的修改
01:03:05 - 01:03:08
so the advantage or disadvantage of each of them are that
So，这两者的优缺点分别是
1.03.08-1.03.12
logical logging allows you to record more changes with less data
Logical Logging允许你使⽤更少的数据去记录更多的修改
01:03:13 - 01:03:15
I update a billion tuples with a single update statement
我可以使⽤⼀条更新语句去更新10亿条tuple
1.03.15-1.03.17
I only know of that one update statement
我只需要知道这⼀条更新语句即可
01:03:18 - 01:03:22
the downsides gonna be with logical logging though is that
Logical Logging的缺点是
01:03:23 - 01:03:32
it's gonna be tricky for me to figure out what changes I potentially may made to the
database that I've got written to disk, before the crash
对于我来说，我难以去弄清楚在系统发⽣崩溃前，我对数据库所做的修改实际有哪些已经被写⼊
磁盘了
01:03:33 - 01:03:35
Because I don't have that low-level information
因为我并没有这些低级层⾯的信息
01:03:36 - 01:03:41
I update a billion tuples over a billion pages maybe half of them got written out the disk
⽐如说：我更新了10亿个page上的10亿个tuple，可能只有⼀半的tuple被写⼊到了磁盘
01:03:41 - 01:03:44
how do I know which ones I need to update and replay
我如何知道我该更新哪个page，我该重新执⾏哪些操作？
01:03:46 - 01:03:47
the other issues gonna be
其他的问题则是
1.03.47-1.03.51
you'll see that however long it took me update the database
不管我更新数据库数据时所花的时间有多⻓
1.03.51-1.03.54
the first time when I ran the query with a logical logging scheme
当我第⼀次使⽤Logical Logging⽅案来执⾏查询时
01:03:54 - 01:03:56
this is gonna take that same amount of time the second time
它所花的时间和第⼆次执⾏该查询时所花的时间相同
01:03:56 - 01:03.58
so my query took an hour to run
So，⽐如说：我这个查询要花1⼩时才能执⾏完毕
1.03.58-1.04.00
during recovery to take an hour to run again
在恢复数据库的时候，执⾏这个查询还是要花1⼩时
01:04:01 - 01:04:01
there's no magic
这⾥并没有什么奇特的地⽅
1.04.01-1.04.03
because I'm in recovery mode that's gonna make that go faster
当我处于恢复模式时，这会使其运⾏得更快
01:04:05 - 01:04:08
so although the scheme storing I'm storing less information of logical logging
So，虽然Logical Logging这种⽅案需要保存的数据较少
1.04.08-1.04.09
it's going to make recovery more expensive
但这会让数据库系统恢复时所付出的成本更加昂贵
1.04.09-1.04.12
and most systems do not make that change
⼤部分数据库系统不会做出这种改变
01:04:13 - 01:04:17
the hybrid approach that most people use is call it physiological logging
⼤部分⼈所使⽤的混合⽅案叫做Physiological Logging
01:04:18 - 01:04:23
where you're not going to store the low level byte information about the changes you're
making to the database
即你⽆须去保存你对数据库所做的那些低级层⾯
01:04:23 - 01:04:30
you're still sort like it's a low level enough to say here at this page, I'm modifying this
object
01:04:30 - 01:04:34
but you're not you're not really taking a diff as you would under physical logging
01:04:34 - 01:04:38
you're just saying here's this logical thing I want you to make up make a change to
01:04:38 - 01:04:40
so this is what most systems actually implement
01:04:41 - 01:04:48
so let's say we have this update query here, so in a physical log it would be like at this
page of this offset here's the before and after image
01:04:49 - 01:04:55
and we haven't talked about indexes as well, but indexes you basic at the log in the at
the same time you're making changes to the database
01:04:55 - 01:05:01
because if my of my index doesn't fit memory ,then I don't want to have to rebuild it
from scratch upon recovery
01:05:01 - 01:05:06
so most DBMS also record the log the changes you makes it indexes
01:05:06 - 01:05:10
logical login of query again you just store the SQL statement
01:05:10 - 01:05:18
physical logical logging is you're saying at this page at this slot number, here's the
change I want you to make these these low-level attributes
01:05:20 - 01:05:27
and this allows you to not have to ,but having these in this extra indirection sort of like
the slotted pages
01:05:27 - 01:05:38
it doesn't allows you to reorder that the the replay operations, in such a way that the the
DBMS mean a byte for byte copy yet before and after the crash
01:05:38 - 01:05:45
you have some wiggle room to actually reapply these in different ways, and restored still
restore back to the correct state
01:05:46 - 01:05:48
all right,
1.05.48-1.05.50
so the getting to her question is
So，这就和她的问题有关了
1.05.50-1.05.54
the issue we talked about so far is that
我们⽬前为⽌所讨论的问题是
1.05.54-1.05.56
these write ahead logs are gonna grow forever
这些预写式⽇志的体积会不断变⼤
01:05:57 - 01:05.59
if my database system is running for a year
如果我的数据库系统运⾏了⼀年
1.05.59-1.06.01
I'm gonna have a years of logs
我就会拥有⼀年份的⽇志
01:06:01 - 01:06:06
so now if I have to crash ,if I crash and come back into replay this log
So，如果我遇上崩溃的情况，当系统恢复后重新执⾏该⽇志上的内容
1.06.06-1.06.08
I potentially have to replay the entire year's worth of data
我可能需要重播这⼀整年的⽇志数据
01:06:10 - 01:06:12
so logical logging that would be terrible
So，Logical Logging⽅案可能就会很可怕
01:06:12 - 01:06:16
right because if the query takes the same amount of time it took the first time as it does
during recovery
01:06:17 - 01:06:20
so I have a year's worth of data of logical log records
1.06.20-
if I crash and come back
I pretend to take a year for me to recover the database
01:06:26 - 01:06:27
so that's bad
So，这很糟糕
1.06.27-1.06.34
so the way we can truncate the log is to what are called checkpoints
So，我们截断⽇志的⽅式叫做checkpoints
01:06:34 - 01:06:36
and the idea of a checkpoint is that
checkpoints的思路是
1.06.36-1.06.41
we're gonna flush out all the pages that are dirty in our buffer pool out the disk
我们会将我们buffer pool中所有dirty page刷出到磁盘
01:06:41 - 01:06:43
and add a entry to our log record to say
并往我们的⽇志记录中添加⼀个条⽬，以此表示
1.06.43-1.06.45
at this point
此时
1.06.45-1.06.48
there's no dirty pages that are not durable in disks
所有的dirty page都被持久化到了磁盘上
01:06:48 - 01:06:49
so therefore
因此
1.06.49-1.06.55
you don't need to replay that far in the past potentially from my checkpoint
你⽆须去重新执⾏过去那么多⽇志，你需要从我的checkpoint处开始执⾏即可
01:06:56 - 01:06:58
because I know all those changes have been persistent
因为我知道checkpoint前的这些修改已经被持久化了
01:06:59 - 01:07:00
again the idea here again
这⾥的思路是
1.07.00-1.07.05
because we're doing the steal policy or the no force policy
因为我们使⽤的是Steal+No-Force策略
01:07:05 - 01:07:10
we're not requiring that the dirty pages that transaction made has to be flushed out the
disk before the transaction is committed
我们并不要求在事务被提交前，该事务所修改的这些dirty page被刷出到磁盘
01:07:11 - 01:07:16
so we don't know whether they actually made it to disk or not，if we crash
So，如果我们崩溃的话，我们并不清楚这些page是否被刷出到磁盘
01:07:16 - 01:07:17
whereas with the checkpoint
然⽽，如果使⽤的是checkpoint的话
1.07.17-1.07.19
when we know the checkpoint completes
我们知道，当这个checkpoint完成的时候
1.07.19-1.07.22
we know that at that point everything has been written a disk
我们知道在这个点上，所有东⻄都已经被写⼊到磁盘
01:07:25 - 01:07:27
so look at really simple example here
So，我们来看个很简单的例⼦
01:07:27 - 01:07:28
so for this one
So，在这个例⼦中
1.07.28-1.07.30
I'm going to use a very simplistic checkpoint scheme
我会使⽤⼀种⾮常简单的checkpoint⽅案
1.07.30-1.07.39
that basically stops the world stops all transactions from running ,and flushes out all
their changes all the dirty pages out to disk
简单来讲，就是停⽌所有正在执⾏的事务，并将它们的相关dirty page刷出到磁盘
01:07:39 - 01:07:41
and then once I know all the dirty pages are written
接着，⼀旦我知道所有的dirty page都落地到磁盘
1.07.41-1.07.43
then I let them to start running again
那么，我会让这些事务再次开始执⾏
01:07:44 - 01:07:48
this is called consistent checkpointing or blocking checkpoints
这种⽅式叫做Consistent Checkpoint或者叫做Blocking Checkpoint
01:07:48 - 01:07:50
most systems don't actually implement it this way
⼤多数数据库系统实际不会以这种⽅式去实现它
1.07.50-1.07.54
we'll see on Wednesday how to do it better and how things can run at the same time
我们会在周三的时候去看下如何将它变得更好，并让这些东⻄同时执⾏
01:07:54 - 01:08:00
but just understand the very basic how the basic protocol works assume that's the case
但我们要去理解下这个基础协议的⼯作⽅式
01:08:00 - 01:08:02
so I'm gonna add this checkpoint entry here
So，我会在这⾥添加个checkpoint条⽬
1.08.02-1.08.04
so what will happen is
So，这⾥所发⽣的事情是
1.08.04-1.08.05
when I take this checkpoint,
当我拿到这个checkpoint时
1.08.05-1.08.07
I stop all transaction from running
我会停⽌所有正在执⾏的事务
1.08.07-1.08.09
and I flush out any dirty pages
接着，我将所有的dirty page刷出到磁盘
01:08:09 - 01:08:11
and so now if I have a crash .
So，现在如果我遇上崩溃
1.08.11-1.08.13
when I come back
当我系统恢复正常的时候
1.08.13-1.08.18
,I know that I don't need to look at any T1's changes
我知道我⽆须去查看T1所做的任何修改
01:08:18 - 01:08:22
because t1 committed before my checkpoint
因为T1在我的checkpoint之前就提交了
1.08.22-1.08.24
so I know all the t1 changes are written a disk
So，我知道T1所做的所有修改都落地到磁盘了
01:08:25 - 01:08:27
so I don't need to replay and look at it's log
So，我⽆须去查看并重新执⾏这段⽇志
01:08:27 - 01:08:29
it's the other two guys t2 and t3
这⾥还有其他两个事务，即T2和T3
1.08.29-1.08.31
those guys get started
这两个事务开始执⾏
1.08.31-1.08.33
and could potentially make change before my checkpoint
它们可能在我的checkpoint之前就执⾏了修改
01:08:33 - 01:08:36
so I need to go back in the log up to that point
So，我需要回到⽇志中这个点的位置
1.08.36-1.08.40
and figure out what they actually did to put my data back in the correct state
并弄清楚它们实际做了什么事情，以此来让我的数据回归正轨
01:08:40 - 01:08:41
so in the case here
So，在这个例⼦中
1.08.41-1.08.44
T2 committed before the crash
T2在崩溃发⽣前就提交了
01:08:44 - 01:08:48
so I know I want to reapply it changes to redo their exchanges
So，我想去重新执⾏它的修改
01:08:48 - 01:08:50
t3 did not commit before the crash
T3并没有在崩溃前提交事务
1.08.50-1.08.52
so I would know I want to reverse its changes
So，我就知道我想去撤销它所做的修改
01:08:54 - 01:09:02
right so the checkpoints basically if your skin is telling us that we know that at this point
in time all dirty pages from any transactions have been written to disk
简单来讲，checkpoint指的是，在这个时间点之前，任何事务所修改的dirty page已经被写⼊到
磁盘了
01:09:03 - 01:09:12
and it's up for us to then figure out ,well what came slightly before the checkpoint and
what came after the checkpoint to decide, who's allowed to actually have their changes
persisted
01:09:15 - 01:09:25
so well game will talk about checkpoints more on Wednesday ,but in my simple example
here, I stalled all the transactions to make my life easier
01:09:25 - 01:09:28
because if I have a transaction that's updating a bunch of pages
因为如果我有⼀个事务，它对⼀堆page进⾏更新
01:09:28 - 01:09:38
I don't want to have the case or it could be I had to do some actual work to figure out,
well I'm updating 20 pages ,and my checkpoint flushed out the first 10 pages that
transaction modified
01:09:38 - 01:09:42
but then while the checkpoint was running it modified these other ones I didn't flush
those things out
01:09:42 - 01:09:45
so I don't want to figure out which ones actually should be around
01:09:47 - 01:09:51
the other tricky thing is gonna be it's not clear how often we should take a checkpoint
01:09:51 - 01:09:53
because these checkpoints aren't free
01:09:53 - 01:09:58
because we're writing out dirty pages and that's slowing slowing the disk,when we could
be running out to a log
01:09:58 - 01:10:04
now in a lot of systems they'll have the disks, the log we stored in separate disks ,and
the heat balls are sort of separate disks
01:10:04 - 01:10:07
so when you do a net syncs on both of them ,you're not slowing down each other
01:10:07 - 01:10:19
but again now my checkpoint is running out dirty pages, when I could have been you
know evicting pages for disk to get new space in my buffer pool to have other
transactions keep on running
01:10:20 - 01:10:23
so how often you take a checkpoint can vary based on the implementation
So，你制作checkpoint的频率取决于你的具体实现
01:10:24 - 01:10:27
so the one approach is to say
So，其中⼀种⽅案是
1.10.27-1.10.31
every after every every minutes or seconds, take the checkpoint
⽐如每分钟或者每秒就制作⼀份checkpoint
01:10:32 - 01:10:33
if I do that
如果我这样做了
1.10.33-1.10.35
then my recovery time is much faster
那么，我的恢复时间就会短很多
1.10.35-1.10.39
because now I don't need to go as far back in the log to figure out what should be
actually persisted
因为我就⽆须跑到⽇志很前⾯的地⽅去弄清楚哪些数据被持久化了
01:10:39 - 01:10:41
because my checkpoint is occurring more frequently
因为我记录checkpoint的频率⾮常频繁
01:10:42 - 01:10:45
because now the checkpoints are slowing me down ,so I'm like my runtime performance
suffers
因为这个原因，这就会让我的运⾏时性能降低
01:10:46 - 01:10:47
another approach which I actually think is better
实际上，我觉得另⼀种⽅案要来得更好
1.10.47-1.10.52
is that the checkpoint only occurs after a certain amount of data that ran out the log
只有当⽇志中的数据满了的时候，我们才会去制作checkpoint
01:10:53 - 01:10:55
like after I've written out 250 megabytes of data to the log
⽐如，当我往⽇志中写⼊250MB⼤⼩的数据后
1.10.55-1.10.57
then I take a checkpoint
然后，我就制作了⼀份checkpoint
01:10:57 - 01:11:00
and that that bounds the amount of time you have to wait
这限制了你必须等待的时间量
1.11.00-1.11.07
,and you don't worry about whether you're taking checkpoints unnecessarily
01:11:07 - 01:11:14
because it's your I know that I only need to look at me but I'd most join fifty megabytes
of the log before at the recover my database
01:11:15 - 01:11:18
again I'm going over this very very very fast cuz we're running out of time
我讲的速度⾮常⾮常快，因为我们没有太多时间了
01:11:18 - 01:11:22
but we'll cover this more detail when we talk about recovery on Wednesday
但我们会在周三讨论恢复的时候，对此进⾏更多介绍
01:11:23 - 01:11:25
so any any high-level questions about checkpoints.
So，关于checkpoints，你们有任何⾼逼格的问题吗？
1.11.25-1.11.30
saying a checkpoint is like garbage collection for the write ahead log
checkpoints就像是对预写式⽇志进⾏垃圾回收
01:11:30 - 01:11:33
but i know that at that point of checkpoint
但我知道，在我制作checkpoint的那个点
01:11:34 - 01:11:37
I don't potentially need to look at anything it came before
我⽆须去查看该checkpoint之前的任何东⻄
01:11:40- 01:11:41
of course
1.11.41-1.11.43
in the extreme case
在极端情况下
1.11.43-1.11.45
if I have it if I would a transaction the runs for days
如果我有⼀个运⾏了好⼏天的事务
01:11:45 - 01:11:46
and I'm taking a checkpoint every five minutes
我会每五分钟设置⼀个checkpoint
1.11.46-1.11.51
, and I need to go back to when that transaction started to figure out what all changes
actually made
我需要回过头去弄清楚该事务开始到现在实际做了哪些修改
01:11:53 - 01:11.54
okay
1.11.54-1.11.55
so as I said
So，正如我说的
1.11.55-1.12.06
write ahead logging is is almost always, the preferable approach that the better
approach to handle avoiding data loss or to make sure that our database is durable on
disk
预写式⽇志始终是⼀种更佳⽅案，它能⽤来避免数据丢失，或者确保我们的数据库持久化到了磁
盘上
01:12:06 - 01:12:09
and the core idea what's gonna how it works is that,
它的核⼼思想是
1.12.09-1.12.12
it's gonna use Steal+ No force buffer pool management policy
它使⽤的是Steal+No-Force buffer pool管理策略
01:12:13 - 01:12:19
it's gonna flush all changes that transactions made to their log records to disk, before
we tell the outside world that a transaction is committed
在我们告诉外界该事务已被提交前，它会将该事务对它们⽇志记录所做的修改全都刷到磁盘上
01:12:20 - 01:12:24
and then in the background of some later point we can flush out there's those dirty
pages
在稍后某个时间点，我们会在后台将这些dirty page刷出去
01:12:24 - 01:12:28
but we have to write the log records first before we can write out the dirty pages that
they modify
在我们可以将这些修改过的dirty page写出之前，我们必须先写到⽇志记录上
01:12:29 - 01:12:34
and so on recovery ,we just undo any changes from uncommitted transactions
So，在recovery这个过程中，我们只需撤销那些未提交事务所做的修改
01:12:34 - 01:12:39
and they redo the commit changes the committed to redo the change of any committed
transactions to make sure that they get applied
它们会重新执⾏任何已被提交事务所做的修改，以确保它们被应⽤
01:12:40 - 01:12:40
yes
请问
01:12:45 - 01:12:48
this question is we have to undo potentially changes on recovery
他的问题是，我们需要撤销恢复过程中所做的修改
1.12.48-1.12.49
again we'll cover that on Wednesday
我们会在周三的时候介绍这个
01:12:50 - 01:12:57
because changes from uncommitted transactions could have those dirty pages could be
written out the disk
因为这些未提交事务所修改的这些dirty page可能会被落地到磁盘上
1.12.55-1.12.57
because we're using the steal policy
因为我们使⽤了Steal策略
01:13:05 - 01:13:08
his question is
他的问题是
1.13.08-1.13.12
other scenarios where upon recovery we would not have to undo
01:13:12 - 01:13:15
because we can look at data art changes actually make it out the disk
因为我们关注的是那些实际已经落地到磁盘的修改
01:13:23 - 01:13:24
No
No
1.13.24-1.13.27
the spoiler would be for Wednesday ,you redo everything
01:13:28 - 01:13:30
you could go through the log of multiple times
你可能会对⽇志进⾏多次遍历
01:13:30 - 01:13:31
you're gonna redo everything
你会重新执⾏所有操作
1.13.31-1.13.33
, but then as you redo
但当你重新执⾏操作的时候
1.13.33-1.13.35
you say oh I see this transaction didn't commit
你表示：Oh，我看到这个事务并未被提交
1.13.35-1.13.39
then you go back and reverse on the log ,and you undo anything that is on
1.13.39-1.13.43
,so you play it safe and you always undo
01:13:43 - 01:13:46
there are some optimizations that I don't think most people do them
我们可以对它们进⾏⼀些优化，但我不觉得⼤部分⼈会做
01:13:49 - 01:13:50
all right
01:13:51 - 01:13:53
So，on Wednesdays class
在周三的课上
1.13.53-
again it would be the second part of what we talked about for logging recovery, is two
things we do after a crash right after a restart
01:13:58 - 01:14:01
how do we use the write ahead log, how to use the check points to put us back in the
correct State
你我们该如何使⽤预写式⽇志，以及该如何使⽤checkpoint来让我们的数据库回归正轨
01:14:01 - 01:14:05
so this is probably the third hardest part of database systems
So，这可能是数据库系统中第三难的地⽅
01:14:06 - 01:14:08
so the thing we're talking about is Aries
So，我们要讨论的东⻄是ARIES
1.14.08-1.14.11
,Aries is the gold standard of how you do database recovery
ARIES是你做数据库恢复的时的⻩⾦准则
1.14.11-1.14.13
I don't know what the textbook calls it Aries
我不清楚教科书上为什么将它叫做ARIES
01:14:14 - 01:14:19
most systems that implement write ahead of all are not gonna call but they're doing
Aries
⼤部分系统实现预写式⽇志的数据库系统，它们使⽤的⽅法其实都是ARIES
01:14:19 - 01:14:23
but everybody that does write ahead logging it's me based on the IBM's protocol from
the 1990s
但所有⼈包括我实现预写式⽇志的⽅式都是基于1990年代IBM所提出的那个协议
01:14:23 - 01:14:26
whether or not they know that they're using their basically using Aries
不管他们知不知道他们使⽤的就是ARIES
01:14:27 - 01:14:27
Okay
01:14:28 - 01:14:29
all right
1.14.29-1.14.32
I'm having office hours now at 1:30
我1:30的时候会在办公室
1.14.32-1.14.35
,and see you guys on Wednesday
周三再会



# Lec20 数据库恢复

数据库恢复有两个阶段：

1. 事物在处理的过程中做一些工作来实现恢复。
2. 失败后去恢复数据库的状态来确保 ACID 特性。


为了防止 WAL 越来越长，设置 CheckPoint 。一旦发送崩溃将会从 CheckPoint 开始读取后续的日志，此时就不需要读取整个日志了。

DBMS 周期性的推进 CheckPoint ，将内容持久化到磁盘中。CheckPoint 以上的已经提交的事务都刷到磁盘中。

CheckPoint 的问题：

1. CheckPoint 时要求数据库是静态的，此时要暂停所有事物，对性能有影响。
2. 需要扫描寻找未提交的事务花费大量的时间。
3. 频率过快影响性能，频率低了积累大量的数据后需要处理很长时间。


## ARIES

主要的想法：

1. WAL 先将日志写入磁盘。STEL + No Force
2. 恢复的时候先做 Redo log
3. 跑了一半的事物回滚 Undo log

实现：

LSN：日志序列号

flushedLSN 在此之前的日志都已刷入磁盘，在此之后的日志还在内存中。

pageLSN 记录了最近一次修改该页的 log 编号。当 page 最近被修改后都要更新 pageLSN 。记录在 page 中。pageLSN <= flushedLSN

recLSN 

lastLSN

MasterRecord 

![20220328144232](https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220328144232.png)

正常运行：

假设：

1. 所有的日志记录都在一个页中。
2. 写入磁盘是原子级别的，也就是要么成功要么失败。
3. 严格 2PL
4. steal + No force

刷盘的操作是连续写，并且同步，锁定。

## TXN-END

事务结束的时候会提交一个 COMMIT ，但当此时和该事务相关的脏页还未完全写入磁盘。等待完全写入的时候会提交一个 TXN-END 。

也就是说 COMMIT 只代表日志进入了磁盘，而 TXN-END 则表示数据进了磁盘，但是此时已经滞后很多了。

![20220328145449](https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220328145449.png)

## ABORT 回滚

prevLSN 该日志的上一条日志的序号。因为并发的缘故，事务的日志并非是连续的。

![20220328145921](https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220328145921.png)

回滚的时候也要记下回滚的日志，回滚日志不需要刷盘。也就是 CLR 日志，CLR 日志永远不需要被回滚。

![20220328160924](https://cdn.jsdelivr.net/gh/weijiew/pic/images/20220328160924.png)

## Fuzzy Checkpointing



## Recovery 算法